{
	"generatedAt": "2026-02-24T00:01:35.738Z",
	"provider": "vercel-ai-gateway",
	"models": [
		{
			"id": "mistral/ministral-3b",
			"tier": "small",
			"label": "Ministral 3B"
		},
		{
			"id": "xai/grok-code-fast-1",
			"tier": "small",
			"label": "Grok Code Fast"
		},
		{
			"id": "cerebras/llama3.1-8b",
			"tier": "small",
			"label": "Llama 3.1 8B"
		},
		{
			"id": "openai/gpt-5.2",
			"tier": "frontier",
			"label": "GPT-5.2"
		},
		{
			"id": "anthropic/claude-opus-4.5",
			"tier": "frontier",
			"label": "Claude Opus 4.5"
		},
		{
			"id": "anthropic/claude-sonnet-4.6",
			"tier": "frontier",
			"label": "Claude Sonnet 4.6"
		},
		{
			"id": "google/gemini-3-pro-preview",
			"tier": "frontier",
			"label": "Gemini 3 Pro"
		},
		{
			"id": "mistral/codestral",
			"tier": "small",
			"label": "Codestral"
		}
	],
	"scenarios": [
		{
			"id": "biome-101b3bb2-fix-lint-consider-more-constructs",
			"title": "fix(lint): consider more constructs as valid test assertions (#9178)",
			"sourceRepo": "biomejs/biome",
			"sourceCommitUrl": "https://github.com/biomejs/biome/commit/101b3bb2658dd2fb7ce562f82b784fd5d068df62",
			"diff": "diff --git a/.changeset/busy-numbers-reply.md b/.changeset/busy-numbers-reply.md\nnew file mode 100644\nindex 000000000000..326f6cd0f2c8\n--- /dev/null\n+++ b/.changeset/busy-numbers-reply.md\n@@ -0,0 +1,25 @@\n+---\n+\"@biomejs/biome\": patch\n+---\n+\n+Fixed [#9172](https://github.com/biomejs/biome/issues/9172) and [#9168](https://github.com/biomejs/biome/issues/9168):\n+Biome now considers more constructs as valid test assertions.\n+\n+Previously, [`assert`](https://vitest.dev/api/assert.html), [`expectTypeOf`](https://vitest.dev/api/expect-typeof.html) and [`assertType`](https://vitest.dev/api/assert-type.html)\n+were not recognized as valid assertions by Biome's linting rules, producing false positives in [`lint/nursery/useExpect`](https://biomejs.dev/linter/rules/use-expect) and other similar rules.\n+\n+Now, these rules will no longer produce errors in test cases that used these constructs instead of `expect`:\n+```ts\n+import { expectTypeOf, assert, assertType } from 'vitest';\n+\n+const myStr = \"Hello from vitest!\";\n+it('should be a string', () => {\n+  expectTypeOf(myStr).toBeString();\n+});\n+test(\"should still be a string\", () => {\n+  assertType<string>(myStr);\n+});\n+it.todo(\"should still still be a string\", () => {\n+  assert(typeof myStr === \"string\");\n+});\n+```\ndiff --git a/crates/biome_js_analyze/src/frameworks/playwright.rs b/crates/biome_js_analyze/src/frameworks/playwright.rs\nindex fd1f25fef13c..a7355fe086c3 100644\n--- a/crates/biome_js_analyze/src/frameworks/playwright.rs\n+++ b/crates/biome_js_analyze/src/frameworks/playwright.rs\n@@ -206,7 +206,13 @@ fn is_expect_expression(expr: &AnyJsExpression) -> bool {\n             if let Ok(name) = id.name()\n                 && let Ok(token) = name.value_token()\n             {\n-                return token.text_trimmed() == \"expect\";\n+                let text = token.text_trimmed();\n+                return text == \"expect\"\n+                // support chai-style `assert` syntax from Vitest\n+                || text == \"assert\"\n+                // Include `expectTypeOf`/`assertType` for type assertions from `expect-type`\n+                || text == \"expectTypeOf\"\n+                || text == \"assertType\";\n             }\n             false\n         }\n@@ -215,6 +221,8 @@ fn is_expect_expression(expr: &AnyJsExpression) -> bool {\n             if let Ok(object) = member.object() {\n                 // Recursively check the object - this handles chained member expressions\n                 // like expect(page).not where the object is itself a member expression\n+                // NB: This is overly permissive for certain Vitest constructs (ex: `expect.stringContaining()`)\n+                // that do not assert anything in and of themselves (see issue #9174)\n                 return is_expect_expression(&object);\n             }\n             false\ndiff --git a/crates/biome_js_analyze/src/lint/nursery/use_expect.rs b/crates/biome_js_analyze/src/lint/nursery/use_expect.rs\nindex 0c3987ab8929..82f6f1d4fee2 100644\n--- a/crates/biome_js_analyze/src/lint/nursery/use_expect.rs\n+++ b/crates/biome_js_analyze/src/lint/nursery/use_expect.rs\n@@ -9,11 +9,17 @@ use biome_rule_options::use_expect::UseExpectOptions;\n use crate::frameworks::playwright::{contains_expect_call, get_test_callback, is_test_call};\n \n declare_lint_rule! {\n-    /// Ensure that test functions contain at least one `expect()` assertion.\n+    /// Ensure that test functions contain at least one `expect()` or similar assertion.\n     ///\n     /// Tests without assertions may pass even when behavior is broken, leading to\n     /// false confidence in the test suite. This rule ensures that every test\n-    /// validates some expected behavior using `expect()`.\n+    /// validates some expected behavior using `expect()` or an allowed variant thereof.\n+    /// \n+    /// ### Allowed `expect` variants\n+    /// \n+    /// - [`assert`](https://www.chaijs.com/api/assert/)\n+    /// - [`expectTypeOf`](https://github.com/mmkal/expect-type)\n+    /// - [`assertType`](https://vitest.dev/api/assert-type)\n     ///\n     /// ## Examples\n     ///\n@@ -36,11 +42,30 @@ declare_lint_rule! {\n     /// ```\n     ///\n     /// ```js\n-    /// test(\"soft assertion\", async ({ page }) => {\n+    /// it(\"soft assertion\", async ({ page }) => {\n     ///     await page.goto(\"/\");\n     ///     await expect.soft(page.locator(\"h1\")).toBeVisible();\n     /// });\n     /// ```\n+    /// \n+    /// Variant assertions are allowed:\n+    /// ```js\n+    /// it(\"returns bar when passed foo\", () => {\n+    ///   assert(myFunc(\"foo\") === \"bar\", \"didn't return bar\");\n+    /// });\n+    /// ```\n+    ///\n+    /// ```ts\n+    /// it(\"should allow passing 'foo' as an argument\", () => {\n+    ///   expectTypeOf(myFunc).toBeCallableWith(\"foo\");\n+    /// });\n+    /// ```\n+    /// ```ts\n+    /// it(\"should have proper type\", () => {\n+    ///   assertType<(n: string) => string>(myFunc);\n+    /// });\n+    /// ```\n+    /// (This replicates the rule's behavior in eslint-plugin-vitest with `typecheck` set to `true`.)\n     ///\n     pub UseExpect {\n         version: \"2.4.2\",\ndiff --git a/crates/biome_js_analyze/tests/specs/nursery/useExpect/valid/vitest-expect-variants.ts b/crates/biome_js_analyze/tests/specs/nursery/useExpect/valid/vitest-expect-variants.ts\nnew file mode 100644\nindex 000000000000..2d4c6418eeae\n--- /dev/null\n+++ b/crates/biome_js_analyze/tests/specs/nursery/useExpect/valid/vitest-expect-variants.ts\n@@ -0,0 +1,24 @@\n+/* should not generate diagnostics */\n+\n+it(\"should typecheck correctly\", () => {\n+  expectTypeOf(\"foo\").not.toEqualTypeOf(\"bar\");\n+});\n+it(\"should be a string\", () => {\n+  assertType<string>(\"foo\");\n+});\n+\n+describe(\"math\", () => {\n+  test(\"1+1\", () => {\n+    assert(1 + 1 === 2);\n+  });\n+});\n+\n+type MyType<T> = (arg: T) => void;\n+\n+describe(\"MyType\", () => {\n+  it(\"should be contravariant\", () => {\n+    // \"foo\" extends string => T<string> extends T<\"foo\">\n+    expectTypeOf(\"foo\").toExtend<string>();\n+    expectTypeOf<MyType<string>>().toExtend<MyType<\"foo\">>();\n+  });\n+});\ndiff --git a/crates/biome_js_analyze/tests/specs/nursery/useExpect/valid/vitest-expect-variants.ts.snap b/crates/biome_js_analyze/tests/specs/nursery/useExpect/valid/vitest-expect-variants.ts.snap\nnew file mode 100644\nindex 000000000000..f88f5610a206\n--- /dev/null\n+++ b/crates/biome_js_analyze/tests/specs/nursery/useExpect/valid/vitest-expect-variants.ts.snap\n@@ -0,0 +1,32 @@\n+---\n+source: crates/biome_js_analyze/tests/spec_tests.rs\n+expression: vitest-expect-variants.ts\n+---\n+# Input\n+```ts\n+/* should not generate diagnostics */\n+\n+it(\"should typecheck correctly\", () => {\n+  expectTypeOf(\"foo\").not.toEqualTypeOf(\"bar\");\n+});\n+it(\"should be a string\", () => {\n+  assertType<string>(\"foo\");\n+});\n+\n+describe(\"math\", () => {\n+  test(\"1+1\", () => {\n+    assert(1 + 1 === 2);\n+  });\n+});\n+\n+type MyType<T> = (arg: T) => void;\n+\n+describe(\"MyType\", () => {\n+  it(\"should be contravariant\", () => {\n+    // \"foo\" extends string => T<string> extends T<\"foo\">\n+    expectTypeOf(\"foo\").toExtend<string>();\n+    expectTypeOf<MyType<string>>().toExtend<MyType<\"foo\">>();\n+  });\n+});\n+\n+```\ndiff --git a/packages/@biomejs/backend-jsonrpc/src/workspace.ts b/packages/@biomejs/backend-jsonrpc/src/workspace.ts\nindex 592bae604c52..e970138bb0bc 100644\n--- a/packages/@biomejs/backend-jsonrpc/src/workspace.ts\n+++ b/packages/@biomejs/backend-jsonrpc/src/workspace.ts\n@@ -2360,7 +2360,7 @@ See https://biomejs.dev/linter/rules/use-exhaustive-switch-cases\n \t */\n \tuseExhaustiveSwitchCases?: UseExhaustiveSwitchCasesConfiguration;\n \t/**\n-\t* Ensure that test functions contain at least one expect() assertion.\n+\t* Ensure that test functions contain at least one expect() or similar assertion.\n See https://biomejs.dev/linter/rules/use-expect \n \t */\n \tuseExpect?: UseExpectConfiguration;\ndiff --git a/packages/@biomejs/biome/configuration_schema.json b/packages/@biomejs/biome/configuration_schema.json\nindex 513779b870c2..4defb9fe5d62 100644\n--- a/packages/@biomejs/biome/configuration_schema.json\n+++ b/packages/@biomejs/biome/configuration_schema.json\n@@ -6198,7 +6198,7 @@\n \t\t\t\t\t]\n \t\t\t\t},\n \t\t\t\t\"useExpect\": {\n-\t\t\t\t\t\"description\": \"Ensure that test functions contain at least one expect() assertion.\\nSee https://biomejs.dev/linter/rules/use-expect\",\n+\t\t\t\t\t\"description\": \"Ensure that test functions contain at least one expect() or similar assertion.\\nSee https://biomejs.dev/linter/rules/use-expect\",\n \t\t\t\t\t\"anyOf\": [\n \t\t\t\t\t\t{ \"$ref\": \"#/$defs/UseExpectConfiguration\" },\n \t\t\t\t\t\t{ \"type\": \"null\" }\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "fix(lint): recognize assert, expectTypeOf, and assertType as valid test assertions",
					"latencyMs": 2148,
					"costUsd": 0.0164,
					"inputTokens": 3175,
					"outputTokens": 21,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 3175,
								"output_tokens": 21,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 1775563.983259,
										"endTime": 1777377.162912,
										"statusCode": 200,
										"providerResponseId": "msg_015oTQVxYNoc5QytSdsvH5aG"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.0164",
							"generationId": "gen_01KJ6F3JVRVPTTNYTTJHEFGTCB",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "fix(nursery/useExpect): recognize assert, expectTypeOf, and assertType as valid assertions",
					"latencyMs": 1577,
					"costUsd": 0.009903,
					"inputTokens": 3176,
					"outputTokens": 25,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 3176,
								"output_tokens": 25,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 91846.598734,
										"endTime": 93057.620479,
										"statusCode": 200,
										"providerResponseId": "msg_01UHV99FaoTV58G8TQNzHduH"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.009903",
							"generationId": "gen_01KJ6F3MZ7MEH6CJWD23KXQW1R",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "fix(core): support Vitest's expect variants",
					"latencyMs": 859,
					"costUsd": 0.0002639,
					"inputTokens": 2629,
					"outputTokens": 10,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 89014.465084,
										"endTime": 89333.139638,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0002639",
							"marketCost": "0.0002639",
							"generationId": "gen_01KJ6F3J66BRA4ZA6YPF8RYW36",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "feat(l",
					"latencyMs": 3549,
					"costUsd": 0.007534,
					"inputTokens": 3071,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 113,
								"promptTokenCount": 3071,
								"candidatesTokenCount": 3,
								"totalTokenCount": 3187,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 1777777.286572,
										"endTime": 1780957.443005,
										"statusCode": 200,
										"providerResponseId": "8OmcaeHkMtuGyOgPv-6ToAI"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.007534",
							"generationId": "gen_01KJ6F3N12365YNY45N01NSMKS",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "fix(analyze): add support for vitest expect variants in useExpect rule",
					"latencyMs": 958,
					"costUsd": 0.00087,
					"inputTokens": 2849,
					"outputTokens": 17,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 93435.061484,
										"endTime": 94050.957656,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00087",
							"marketCost": "0.00087",
							"generationId": "gen_01KJ6F3PGW46XEV1SN75VJQNDD",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "fix(lint): allow `assert`, `expectTypeOf`, `assertType` in test assertions for Vitest",
					"latencyMs": 887,
					"costUsd": 0.00011492,
					"inputTokens": 2849,
					"outputTokens": 24,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 1774228.590959,
										"endTime": 1774588.930759,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00011492",
							"marketCost": "0.00011492",
							"generationId": "gen_01KJ6F3J6NYK0BNER6VB4XHFET",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "fix(analyze): treat Vitest assert/expectTypeOf/assertType as assertions",
					"latencyMs": 2206,
					"costUsd": 0.0048825,
					"inputTokens": 2630,
					"outputTokens": 20,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_0ce11ffa0e14182e00699ce9ef0bec8190b50ffac26a60b809",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 874858.595643,
										"endTime": 876719.986779,
										"statusCode": 200,
										"providerResponseId": "resp_0ce11ffa0e14182e00699ce9ef0bec8190b50ffac26a60b809"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.0048825",
							"generationId": "gen_01KJ6F3JV34ZWDM0DZ71DKN72B",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "feat(lint): extend useExpect rule to recognize assert, expectTypeOf, and assertType assertions",
					"latencyMs": 13688,
					"costUsd": 0.00102234,
					"inputTokens": 2742,
					"outputTokens": 339,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 892926.133541,
										"endTime": 906088.856526,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00102234",
							"marketCost": "0.00102234",
							"generationId": "gen_01KJ6F3J64P1SY9N81X9QB85SM",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "biome-f87acf67-feat-graphql-as-valid-graphql-tag",
			"title": "feat: graphql as valid graphql tag (#9163)",
			"sourceRepo": "biomejs/biome",
			"sourceCommitUrl": "https://github.com/biomejs/biome/commit/f87acf675ebeca794878158cd122496b9c271673",
			"diff": "diff --git a/.changeset/two-signs-try.md b/.changeset/two-signs-try.md\nnew file mode 100644\nindex 000000000000..50a95304a1d3\n--- /dev/null\n+++ b/.changeset/two-signs-try.md\n@@ -0,0 +1,20 @@\n+---\n+\"@biomejs/biome\": patch\n+---\n+\n+Added `graphql` to valid embedded graphql template tags inside JavaScript files, when the feature `javascript.experimentalEmbeddedSnippetsEnabled` is enabled. This allows proper support for graphql tags used in RelayJS.\n+\n+Now, code snippets like the following are correctly formatted and limited:\n+\n+```js\n+import { graphql } from \"react-relay\";\n+\n+const query = graphql`\n+  query {\n+    user(id: 1) {\n+      id\n+      name\n+    }\n+  }\n+`;\n+```\ndiff --git a/crates/biome_service/src/file_handlers/javascript.rs b/crates/biome_service/src/file_handlers/javascript.rs\nindex 3ce05908a693..7e6c1321c020 100644\n--- a/crates/biome_service/src/file_handlers/javascript.rs\n+++ b/crates/biome_service/src/file_handlers/javascript.rs\n@@ -694,9 +694,11 @@ fn is_styled_tag(tag: Option<&AnyJsExpression>) -> bool {\n }\n \n fn is_graphql_tag(tag: Option<&AnyJsExpression>, template: &JsTemplateExpression) -> bool {\n-    // gql``\n+    // gql`` or graphql``\n     if let Some(AnyJsExpression::JsIdentifierExpression(ident)) = tag\n-        && ident.name().is_ok_and(|name| name.has_name(\"gql\"))\n+        && ident\n+            .name()\n+            .is_ok_and(|name| name.has_name(\"gql\") || name.has_name(\"graphql\"))\n     {\n         return true;\n     }\ndiff --git a/crates/biome_service/src/workspace/server.tests.rs b/crates/biome_service/src/workspace/server.tests.rs\nindex 2a609f6a04eb..a96dc11cfba5 100644\n--- a/crates/biome_service/src/workspace/server.tests.rs\n+++ b/crates/biome_service/src/workspace/server.tests.rs\n@@ -570,7 +570,15 @@ const Bar = graphql(`\n        id: $peopleId){\n        totalCount\n        }}\n-`);\"#;\n+`);\n+\n+const Baz = graphql`\n+  query PeopleCount {\n+  people(\n+       id: $peopleId){\n+       totalCount\n+       }}\n+`;\"#;\n \n     let fs = MemoryFileSystem::default();\n     fs.insert(Utf8PathBuf::from(FILE_PATH), FILE_CONTENT);\n@@ -628,5 +636,13 @@ const Bar = graphql(`\n     \t\t}\n     \t}\n     `);\n+\n+    const Baz = graphql`\n+    \tquery PeopleCount {\n+    \t\tpeople(id: $peopleId) {\n+    \t\t\ttotalCount\n+    \t\t}\n+    \t}\n+    `;\n     \");\n }\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "feat(javascript): add graphql tag support for embedded GraphQL snippets",
					"latencyMs": 1670,
					"costUsd": 0.00611,
					"inputTokens": 1132,
					"outputTokens": 18,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 1132,
								"output_tokens": 18,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 2596119.677165,
										"endTime": 2597596.165944,
										"statusCode": 200,
										"providerResponseId": "msg_01GKHP7gSTEAsqKhdeyTmdm4"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00611",
							"generationId": "gen_01KJ6F403PQDY0NDT0DS6QAVM7",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "feat(service): add `graphql` as valid embedded GraphQL template tag identifier",
					"latencyMs": 1436,
					"costUsd": 0.003699,
					"inputTokens": 1133,
					"outputTokens": 20,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 1133,
								"output_tokens": 20,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 1689468.003061,
										"endTime": 1690712.182528,
										"statusCode": 200,
										"providerResponseId": "msg_01KaMViDmsFqhbGyjsRwTbtY"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.003699",
							"generationId": "gen_01KJ6F41G6V07Y6KJ11DF2TC5S",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(core): add support for graphql tags in javascript files",
					"latencyMs": 905,
					"costUsd": 0.0000923,
					"inputTokens": 911,
					"outputTokens": 12,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 2596675.744059,
										"endTime": 2597388.123948,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0000923",
							"marketCost": "0.0000923",
							"generationId": "gen_01KJ6F3Z7AG42Z8TSKPXPM2XNM",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "feat(",
					"latencyMs": 3525,
					"costUsd": 0.00352,
					"inputTokens": 1064,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 114,
								"promptTokenCount": 1064,
								"candidatesTokenCount": 2,
								"totalTokenCount": 1180,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 1790796.181012,
										"endTime": 1794115.939278,
										"statusCode": 200,
										"providerResponseId": "_emcacqvNYmhyOgPvaaUuQ0"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00352",
							"generationId": "gen_01KJ6F41QXSJ0JWFQQD3RFY8ND",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "feat(core): add support for graphql template tags in JavaScript files",
					"latencyMs": 619,
					"costUsd": 0.0003096,
					"inputTokens": 984,
					"outputTokens": 16,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 2600430.878512,
										"endTime": 2600757.080001,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0003096",
							"marketCost": "0.0003096",
							"generationId": "gen_01KJ6F42WW21CS3APMRWE7FCYY",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "feat(js): add support for `graphql` template tags in JS files when `experimentalEmbeddedSnippetsEnabled` is enabled",
					"latencyMs": 485,
					"costUsd": 0.00004052,
					"inputTokens": 984,
					"outputTokens": 29,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 1787582.492097,
										"endTime": 1787877.401887,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00004052",
							"marketCost": "0.00004052",
							"generationId": "gen_01KJ6F3Z805QJNMVGXJCTNXDZR",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "fix(biome_service): support graphql tagged templates as embedded GraphQL snippets",
					"latencyMs": 1849,
					"costUsd": 0.0018375,
					"inputTokens": 898,
					"outputTokens": 19,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_09b587af10bd04f800699ce9fc2c348191984392ff8c2e8cb9",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 906757.685903,
										"endTime": 908424.605707,
										"statusCode": 200,
										"providerResponseId": "resp_09b587af10bd04f800699ce9fc2c348191984392ff8c2e8cb9"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.0018375",
							"generationId": "gen_01KJ6F3ZPJY12AZDD43KT7E8WP",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "feat(javascript): add support for graphql template tags",
					"latencyMs": 9800,
					"costUsd": 0.00068964,
					"inputTokens": 1071,
					"outputTokens": 340,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 1151788.979757,
										"endTime": 1161380.945896,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00068964",
							"marketCost": "0.00068964",
							"generationId": "gen_01KJ6F3Z7Q1XHMAQR3SDP9XYTK",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "giselle-cc560173-refactor-output-format-into-out",
			"title": "Refactor output format into OutputConfiguration discriminated union",
			"sourceRepo": "giselles-ai/giselle",
			"sourceCommitUrl": "https://github.com/giselles-ai/giselle/commit/cc560173bd5754a3d8757fc5447e59f8dc91d309",
			"diff": "diff --git a/.continuity/20260219-200700-feat__add-structured-output-schema.md b/.continuity/20260219-200700-feat__add-structured-output-schema.md\nnew file mode 100644\nindex 0000000000..7e53919c40\n--- /dev/null\n+++ b/.continuity/20260219-200700-feat__add-structured-output-schema.md\n@@ -0,0 +1,60 @@\n+# Continuity ledger (per-branch)\n+\n+## Human intent (must not be overwritten)\n+\n+- Add structured output schema support to the protocol layer\n+- Use discriminated union pattern to make illegal states (e.g., `outputFormat: \"text\"` with a `structuredOutputSchema`) unrepresentable\n+- Follow existing codebase patterns (nested discriminated union as field value, not flat intersection)\n+\n+## Goal (incl. success criteria)\n+\n+- `OutputConfiguration` discriminated union in `structured-output.ts` ensures `structuredOutputSchema` only exists when `outputFormat: \"json\"`\n+- Field name `outputConfiguration` (not `outputFormat`) avoids `x.x` redundancy, matching existing patterns like `auth.type`, `state.status`\n+- All consumers updated, format/build/types/tidy/tests pass\n+\n+## Constraints/Assumptions\n+\n+- Follow existing discriminated union pattern: nested as field value, field name differs from discriminator key\n+- Keep `OutputConfiguration` in `structured-output.ts` (root-level shared schema, consistent with `connection.ts` pattern)\n+\n+## Key decisions\n+\n+- Renamed `OutputFormat` → `OutputConfiguration` (schema + type export)\n+- Field name: `outputConfiguration` (avoids `outputFormat.outputFormat` redundancy)\n+- Nested approach (not flat `z.intersection`/`extend`), consistent with all other discriminated unions in the codebase\n+\n+## State\n+\n+- All changes complete, all quality checks pass\n+\n+## Done\n+\n+- Defined `OutputConfiguration` discriminated union in `structured-output.ts`\n+- Updated `text-generation.ts` and `content-generation.ts` to use `outputConfiguration: OutputConfiguration`\n+- Updated `node-conversion.ts` to pass `outputConfiguration` as a single object (no manual spread)\n+- Updated `node-factories.ts` create functions\n+- Updated all test fixtures and assertions\n+- format, build-sdk, check-types, tidy, test all pass\n+\n+## Now\n+\n+- Complete\n+\n+## Next\n+\n+- Commit changes if requested\n+\n+## Open questions (UNCONFIRMED if needed)\n+\n+- None\n+\n+## Working set (files/ids/commands)\n+\n+- `packages/protocol/src/structured-output.ts`\n+- `packages/protocol/src/node/operations/text-generation.ts`\n+- `packages/protocol/src/node/operations/content-generation.ts`\n+- `packages/node-registry/src/node-conversion.ts`\n+- `packages/node-registry/src/node-factories.ts`\n+- `packages/node-registry/src/node-conversion.test.ts`\n+- `packages/node-registry/src/__fixtures__/node-conversion/nodes.ts`\n+- `packages/react/src/workspace/utils/is-supported-connection.test.ts`\ndiff --git a/packages/node-registry/src/__fixtures__/node-conversion/nodes.ts b/packages/node-registry/src/__fixtures__/node-conversion/nodes.ts\nindex a04f49998d..fd5e818d46 100644\n--- a/packages/node-registry/src/__fixtures__/node-conversion/nodes.ts\n+++ b/packages/node-registry/src/__fixtures__/node-conversion/nodes.ts\n@@ -32,7 +32,7 @@ export const openAI_1 = {\n \t\tprompt:\n \t\t\t'{\"type\":\"doc\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"京都市右京区太秦、太映通り商店街に「アララ」という洋食店はありますか？Webを検索し\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Yes/Noのみを出力してください。\"}]}]}',\n \t\ttools: { openaiWebSearch: { searchContextSize: \"medium\" } },\n-\t\toutputFormat: \"text\",\n+\t\toutputConfiguration: { outputFormat: \"text\" },\n \t},\n };\n \n@@ -70,7 +70,7 @@ export const openAIWithGitHubTool = {\n \t\t\t\tauth: { type: \"secret\", secretId: \"scrt-TESTTESTTESTTEST\" },\n \t\t\t},\n \t\t},\n-\t\toutputFormat: \"text\",\n+\t\toutputConfiguration: { outputFormat: \"text\" },\n \t},\n };\n \n@@ -102,7 +102,7 @@ export const openAIWithoutTools = {\n \t\t},\n \t\tprompt:\n \t\t\t'{\"type\":\"doc\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"hello\"}]}]}',\n-\t\toutputFormat: \"text\",\n+\t\toutputConfiguration: { outputFormat: \"text\" },\n \t},\n };\n \n@@ -134,7 +134,7 @@ export const openAIWithEmptyTools = {\n \t\tprompt:\n \t\t\t'{\"type\":\"doc\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Please tell me React.js\"}]}]}',\n \t\ttools: {},\n-\t\toutputFormat: \"text\",\n+\t\toutputConfiguration: { outputFormat: \"text\" },\n \t},\n };\n \n@@ -163,7 +163,7 @@ export const anthropicClaudeSonnet = {\n \t\t},\n \t\tprompt:\n \t\t\t'{\"type\":\"doc\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"前提条件\"},{\"type\":\"text\",\"text\":\"：\"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"Nは100〜250の整数\"},{\"type\":\"text\",\"text\":\"。\"}]},{\"type\":\"bulletList\",\"content\":[{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"(a) \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"9の倍数\"},{\"type\":\"text\",\"text\":\"。\"}]}]},{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"(b) \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"5の倍数\"},{\"type\":\"text\",\"text\":\"。\"}]}]},{\"type\":\"listItem\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"(c) \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"7進表記で回文（3桁）\"},{\"type\":\"text\",\"text\":\"、すなわち \"},{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"N = 50a + 7b\"},{\"type\":\"text\",\"text\":\"（a∈{2,3,4}, b∈{0..6}）。\"}]}]}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"marks\":[{\"type\":\"bold\"}],\"text\":\"問\"},{\"type\":\"text\",\"text\":\"：Nを求めよ。\"}]},{\"type\":\"paragraph\"},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"You must outputs number only\"}]}]}',\n-\t\toutputFormat: \"text\",\n+\t\toutputConfiguration: { outputFormat: \"text\" },\n \t},\n };\n \n@@ -192,7 +192,7 @@ export const anthropicClaudeOpus45 = {\n \t\t},\n \t\tprompt:\n \t\t\t'{\"type\":\"doc\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Solve x^2 + 4x + 4 = 0.\"}]}]}',\n-\t\toutputFormat: \"text\",\n+\t\toutputConfiguration: { outputFormat: \"text\" },\n \t},\n };\n \n@@ -227,6 +227,6 @@ export const googleGemini = {\n \t\t},\n \t\tprompt:\n \t\t\t'{\"type\":\"doc\",\"content\":[{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"京都市右京区太秦、太映通り商店街に「アララ」という洋食店はありますか？Webを検索し\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Yes/Noのみを出力してください。\"}]}]}',\n-\t\toutputFormat: \"text\",\n+\t\toutputConfiguration: { outputFormat: \"text\" },\n \t},\n };\ndiff --git a/packages/node-registry/src/node-conversion.test.ts b/packages/node-registry/src/node-conversion.test.ts\nindex 3eeac24d16..cd34401922 100644\n--- a/packages/node-registry/src/node-conversion.test.ts\n+++ b/packages/node-registry/src/node-conversion.test.ts\n@@ -43,7 +43,7 @@ function createOpenAITextNode(\n \t\t\t\t},\n \t\t\t},\n \t\t\tprompt: \"test\",\n-\t\t\toutputFormat: \"text\",\n+\t\t\toutputConfiguration: { outputFormat: \"text\" },\n \t\t},\n \t};\n }\n@@ -357,8 +357,8 @@ describe(\"node-conversion\", () => {\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(originalNode.content.llm.id);\n \t\t\texpect(convertedBack.content.prompt).toBe(originalNode.content.prompt);\n-\t\t\texpect(convertedBack.content.outputFormat).toBe(\n-\t\t\t\toriginalNode.content.outputFormat,\n+\t\t\texpect(convertedBack.content.outputConfiguration).toEqual(\n+\t\t\t\toriginalNode.content.outputConfiguration,\n \t\t\t);\n \t\t\texpect(convertedBack.content.tools?.openaiWebSearch).toBeDefined();\n \t\t});\n@@ -377,8 +377,8 @@ describe(\"node-conversion\", () => {\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(originalNode.content.llm.id);\n \t\t\texpect(convertedBack.content.prompt).toBe(originalNode.content.prompt);\n-\t\t\texpect(convertedBack.content.outputFormat).toBe(\n-\t\t\t\toriginalNode.content.outputFormat,\n+\t\t\texpect(convertedBack.content.outputConfiguration).toEqual(\n+\t\t\t\toriginalNode.content.outputConfiguration,\n \t\t\t);\n \t\t\texpect(convertedBack.content.tools?.github).toBeDefined();\n \t\t\texpect(convertedBack.content.tools?.github?.auth.type).toBe(\"secret\");\n@@ -406,8 +406,8 @@ describe(\"node-conversion\", () => {\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(originalNode.content.llm.id);\n \t\t\texpect(convertedBack.content.prompt).toBe(originalNode.content.prompt);\n-\t\t\texpect(convertedBack.content.outputFormat).toBe(\n-\t\t\t\toriginalNode.content.outputFormat,\n+\t\t\texpect(convertedBack.content.outputConfiguration).toEqual(\n+\t\t\t\toriginalNode.content.outputConfiguration,\n \t\t\t);\n \t\t\texpect(convertedBack.content.tools).toBeUndefined();\n \t\t});\n@@ -426,8 +426,8 @@ describe(\"node-conversion\", () => {\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(originalNode.content.llm.id);\n \t\t\texpect(convertedBack.content.prompt).toBe(originalNode.content.prompt);\n-\t\t\texpect(convertedBack.content.outputFormat).toBe(\n-\t\t\t\toriginalNode.content.outputFormat,\n+\t\t\texpect(convertedBack.content.outputConfiguration).toEqual(\n+\t\t\t\toriginalNode.content.outputConfiguration,\n \t\t\t);\n \t\t});\n \n@@ -445,8 +445,8 @@ describe(\"node-conversion\", () => {\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(originalNode.content.llm.id);\n \t\t\texpect(convertedBack.content.prompt).toBe(originalNode.content.prompt);\n-\t\t\texpect(convertedBack.content.outputFormat).toBe(\n-\t\t\t\toriginalNode.content.outputFormat,\n+\t\t\texpect(convertedBack.content.outputConfiguration).toEqual(\n+\t\t\t\toriginalNode.content.outputConfiguration,\n \t\t\t);\n \t\t});\n \n@@ -464,8 +464,8 @@ describe(\"node-conversion\", () => {\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(originalNode.content.llm.id);\n \t\t\texpect(convertedBack.content.prompt).toBe(originalNode.content.prompt);\n-\t\t\texpect(convertedBack.content.outputFormat).toBe(\n-\t\t\t\toriginalNode.content.outputFormat,\n+\t\t\texpect(convertedBack.content.outputConfiguration).toEqual(\n+\t\t\t\toriginalNode.content.outputConfiguration,\n \t\t\t);\n \t\t});\n \n@@ -485,8 +485,8 @@ describe(\"node-conversion\", () => {\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(originalNode.content.llm.id);\n \t\t\texpect(convertedBack.content.prompt).toBe(originalNode.content.prompt);\n-\t\t\texpect(convertedBack.content.outputFormat).toBe(\n-\t\t\t\toriginalNode.content.outputFormat,\n+\t\t\texpect(convertedBack.content.outputConfiguration).toEqual(\n+\t\t\t\toriginalNode.content.outputConfiguration,\n \t\t\t);\n \t\t});\n \n@@ -505,8 +505,8 @@ describe(\"node-conversion\", () => {\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(originalNode.content.llm.id);\n \t\t\texpect(convertedBack.content.prompt).toBe(originalNode.content.prompt);\n-\t\t\texpect(convertedBack.content.outputFormat).toBe(\n-\t\t\t\toriginalNode.content.outputFormat,\n+\t\t\texpect(convertedBack.content.outputConfiguration).toEqual(\n+\t\t\t\toriginalNode.content.outputConfiguration,\n \t\t\t);\n \t\t\texpect(convertedBack.content.llm?.id).toBe(\"gpt-5.1-thinking\");\n \t\t});\ndiff --git a/packages/node-registry/src/node-conversion.ts b/packages/node-registry/src/node-conversion.ts\nindex 9fc432f403..b59ea0169a 100644\n--- a/packages/node-registry/src/node-conversion.ts\n+++ b/packages/node-registry/src/node-conversion.ts\n@@ -200,8 +200,7 @@ export function convertTextGenerationToContentGeneration(\n \t\t\tlanguageModel,\n \t\t\ttools,\n \t\t\tprompt: textGenerationContent.prompt ?? \"\",\n-\t\t\toutputFormat: textGenerationContent.outputFormat,\n-\t\t\tstructuredOutputSchema: textGenerationContent.structuredOutputSchema,\n+\t\t\toutputConfiguration: textGenerationContent.outputConfiguration,\n \t\t},\n \t};\n }\n@@ -342,8 +341,7 @@ export function convertContentGenerationToTextGeneration(\n \t\t\tllm,\n \t\t\tprompt: contentGenerationContent.prompt,\n \t\t\ttools: toolsToInclude,\n-\t\t\toutputFormat: contentGenerationContent.outputFormat,\n-\t\t\tstructuredOutputSchema: contentGenerationContent.structuredOutputSchema,\n+\t\t\toutputConfiguration: contentGenerationContent.outputConfiguration,\n \t\t},\n \t};\n }\ndiff --git a/packages/node-registry/src/node-factories.ts b/packages/node-registry/src/node-factories.ts\nindex 8476d6e046..d1fbe8a719 100644\n--- a/packages/node-registry/src/node-factories.ts\n+++ b/packages/node-registry/src/node-factories.ts\n@@ -194,7 +194,7 @@ const textGenerationFactoryImpl = {\n \t\t\tcontent: {\n \t\t\t\ttype: \"textGeneration\",\n \t\t\t\tllm,\n-\t\t\t\toutputFormat: \"text\",\n+\t\t\t\toutputConfiguration: { outputFormat: \"text\" },\n \t\t\t},\n \t\t\tinputs: [],\n \t\t\toutputs,\n@@ -832,7 +832,7 @@ const contentGenerationFactoryImpl = {\n \t\t\t\t\tconfiguration: languageModel.defaultConfiguration,\n \t\t\t\t},\n \t\t\t\ttools: [],\n-\t\t\t\toutputFormat: \"text\",\n+\t\t\t\toutputConfiguration: { outputFormat: \"text\" },\n \t\t\t},\n \t\t\tinputs: [],\n \t\t\toutputs,\ndiff --git a/packages/protocol/src/node/operations/content-generation.ts b/packages/protocol/src/node/operations/content-generation.ts\nindex c3aebb13a7..2d8a5b78f9 100644\n--- a/packages/protocol/src/node/operations/content-generation.ts\n+++ b/packages/protocol/src/node/operations/content-generation.ts\n@@ -7,7 +7,7 @@ import {\n \ttype LanguageModelToolName,\n } from \"@giselles-ai/language-model-registry\";\n import * as z from \"zod/v4\";\n-import { StructuredOutputSchema } from \"../../structured-output\";\n+import { OutputConfiguration } from \"../../structured-output\";\n \n export const ContentGenerationContent = z.object({\n \ttype: z.literal(\"contentGeneration\"),\n@@ -26,8 +26,7 @@ export const ContentGenerationContent = z.object({\n \t\t}),\n \t),\n \tprompt: z.string(),\n-\toutputFormat: z.enum([\"text\", \"json\"]).default(\"text\"),\n-\tstructuredOutputSchema: StructuredOutputSchema.optional(),\n+\toutputConfiguration: OutputConfiguration,\n });\n \n export type ContentGenerationContent = z.infer<typeof ContentGenerationContent>;\ndiff --git a/packages/protocol/src/node/operations/text-generation.ts b/packages/protocol/src/node/operations/text-generation.ts\nindex 079846e57b..db7dd51a26 100644\n--- a/packages/protocol/src/node/operations/text-generation.ts\n+++ b/packages/protocol/src/node/operations/text-generation.ts\n@@ -6,7 +6,7 @@ import {\n } from \"@giselles-ai/language-model\";\n import * as z from \"zod/v4\";\n import { SecretId } from \"../../secret\";\n-import { StructuredOutputSchema } from \"../../structured-output\";\n+import { OutputConfiguration } from \"../../structured-output\";\n \n export const AnthropicLanguageModelData = AnthropicLanguageModel.pick({\n \tprovider: true,\n@@ -122,8 +122,7 @@ export const TextGenerationContent = z.object({\n \tllm: TextGenerationLanguageModelData,\n \tprompt: z.string().optional(),\n \ttools: z.optional(ToolSet),\n-\toutputFormat: z.enum([\"text\", \"json\"]).default(\"text\"),\n-\tstructuredOutputSchema: StructuredOutputSchema.optional(),\n+\toutputConfiguration: OutputConfiguration,\n });\n export type TextGenerationContent = z.infer<typeof TextGenerationContent>;\n \ndiff --git a/packages/protocol/src/structured-output.ts b/packages/protocol/src/structured-output.ts\nindex 672f34fdd3..39c51716f8 100644\n--- a/packages/protocol/src/structured-output.ts\n+++ b/packages/protocol/src/structured-output.ts\n@@ -62,5 +62,13 @@ export const StructuredOutputSchema = z.object({\n \tadditionalProperties: z.literal(false),\n \trequired: z.array(z.string()),\n });\n-\n export type StructuredOutputSchema = z.infer<typeof StructuredOutputSchema>;\n+\n+export const OutputConfiguration = z.discriminatedUnion(\"outputFormat\", [\n+\tz.object({ outputFormat: z.literal(\"text\") }),\n+\tz.object({\n+\t\toutputFormat: z.literal(\"json\"),\n+\t\tstructuredOutputSchema: StructuredOutputSchema,\n+\t}),\n+]);\n+export type OutputConfiguration = z.infer<typeof OutputConfiguration>;\ndiff --git a/packages/react/src/workspace/utils/is-supported-connection.test.ts b/packages/react/src/workspace/utils/is-supported-connection.test.ts\nindex f2eb567979..2a190b1456 100644\n--- a/packages/react/src/workspace/utils/is-supported-connection.test.ts\n+++ b/packages/react/src/workspace/utils/is-supported-connection.test.ts\n@@ -42,7 +42,7 @@ describe(\"isSupportedConnection\", () => {\n \t\t\tcontent: {\n \t\t\t\ttype: \"textGeneration\",\n \t\t\t\tllm,\n-\t\t\t\toutputFormat: \"text\",\n+\t\t\t\toutputConfiguration: { outputFormat: \"text\" },\n \t\t\t},\n \t\t}) satisfies TextGenerationNode;\n \tconst createImageGenerationNode = (\n@@ -220,7 +220,7 @@ describe(\"isSupportedConnection\", () => {\n \t\t\t\tconfiguration: {},\n \t\t\t},\n \t\t\ttools: [],\n-\t\t\toutputFormat: \"text\",\n+\t\t\toutputConfiguration: { outputFormat: \"text\" },\n \t\t},\n \t});\n \n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "feat(protocol): add OutputConfiguration discriminated union for structured output",
					"latencyMs": 2578,
					"costUsd": 0.02877,
					"inputTokens": 5674,
					"outputTokens": 16,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 5674,
								"output_tokens": 16,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 1699288.343562,
										"endTime": 1701447.843586,
										"statusCode": 200,
										"providerResponseId": "msg_01GSxpNRYjkE6275PJtMq5y9"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.02877",
							"generationId": "gen_01KJ6F49SDRNZXFMRTZ7S3ZD2X",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "refactor(protocol): replace outputFormat/structuredOutputSchema with OutputConfiguration discriminated union",
					"latencyMs": 2112,
					"costUsd": 0.017355,
					"inputTokens": 5675,
					"outputTokens": 22,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 5675,
								"output_tokens": 22,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 2608794.323643,
										"endTime": 2610562.290702,
										"statusCode": 200,
										"providerResponseId": "msg_01LNDapFKtXYqpiT48maqHyp"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.017355",
							"generationId": "gen_01KJ6F4BGW38YM8K4ME9J3GH0C",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(protocol): add structured output schema support",
					"latencyMs": 788,
					"costUsd": 0.0004401,
					"inputTokens": 4392,
					"outputTokens": 9,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 2606631.681482,
										"endTime": 2607067.486479,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0004401",
							"marketCost": "0.0004401",
							"generationId": "gen_01KJ6F48YKD8FJJKZH75H5HHXB",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "feat(",
					"latencyMs": 3269,
					"costUsd": 0.012062,
					"inputTokens": 5335,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 114,
								"promptTokenCount": 5335,
								"candidatesTokenCount": 2,
								"totalTokenCount": 5451,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 1929263.461356,
										"endTime": 1932180.412166,
										"statusCode": 200,
										"providerResponseId": "COqcaYLvI9bVle0PwMGKmAo"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.012062",
							"generationId": "gen_01KJ6F4C7BC42VCE957TA0KJCC",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "feat(protocol): add structured output schema support to protocol layer",
					"latencyMs": 751,
					"costUsd": 0.0014505,
					"inputTokens": 4796,
					"outputTokens": 13,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 1803414.723729,
										"endTime": 1803825.634355,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0014505",
							"marketCost": "0.0014505",
							"generationId": "gen_01KJ6F4DJF9RNNPC0J5C5T1G10",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "feat(protocol): refactor output format to use discriminated union `OutputConfiguration",
					"latencyMs": 664,
					"costUsd": 0.00019256,
					"inputTokens": 4796,
					"outputTokens": 18,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 2606613.690675,
										"endTime": 2606948.057771,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00019256",
							"marketCost": "0.00019256",
							"generationId": "gen_01KJ6F48Y2ZDRRV7W8X411ZT4G",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "feat(protocol): add OutputConfiguration union and migrate outputFormat usage",
					"latencyMs": 1963,
					"costUsd": 0.00798175,
					"inputTokens": 4433,
					"outputTokens": 16,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_05a0366af10f127800699cea064cb08190a64556efdb48fe2e",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 2606434.029633,
										"endTime": 2608061.548777,
										"statusCode": 200,
										"providerResponseId": "resp_05a0366af10f127800699cea064cb08190a64556efdb48fe2e"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00798175",
							"generationId": "gen_01KJ6F49JVJP3CVKYFY8G8ZTV0",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "feat(protocol): add structured output schema support with discriminated union",
					"latencyMs": 11447,
					"costUsd": 0.00123684,
					"inputTokens": 4467,
					"outputTokens": 252,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 2605778.915139,
										"endTime": 2616883.353635,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00123684",
							"marketCost": "0.00123684",
							"generationId": "gen_01KJ6F48Y40PG7JNMTCFKP04E9",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "openclaw-5a475259-fix-telegram-suppress-reasonin",
			"title": "fix(telegram): suppress reasoning-only leaks when reasoning is off",
			"sourceRepo": "openclaw/openclaw",
			"sourceCommitUrl": "https://github.com/openclaw/openclaw/commit/5a475259bb4af18da06aab0eb8ceb86b50caf5f2",
			"diff": "diff --git a/CHANGELOG.md b/CHANGELOG.md\nindex 6b726dfefd40..8fbddabe05f1 100644\n--- a/CHANGELOG.md\n+++ b/CHANGELOG.md\n@@ -24,6 +24,7 @@ Docs: https://docs.openclaw.ai\n - Sessions/Store: canonicalize inbound mixed-case session keys for metadata and route updates, and migrate legacy case-variant entries to a single lowercase key to prevent duplicate sessions and missing TUI/WebUI history. (#9561) Thanks @hillghost86.\n - Telegram/Reactions: soft-fail reaction action errors (policy/token/emoji/API), accept snake_case `message_id`, and fallback to inbound message-id context when explicit `messageId` is omitted so DM reactions stay stable without regeneration loops. (#20236, #21001) Thanks @PeterShanxin and @vincentkoc.\n - Telegram/Polling: scope persisted polling offsets to bot identity and reuse a single awaited runner-stop path on abort/retry, preventing cross-token offset bleed and overlapping pollers during restart/error recovery. (#10850, #11347) Thanks @talhaorak, @anooprdawar, and @vincentkoc.\n+- Telegram/Reasoning: when `/reasoning off` is active, suppress reasoning-only delivery segments and block raw fallback resend of suppressed `Reasoning:`/`<think>` text, preventing internal reasoning leakage in legacy sessions while preserving answer delivery. (#24626, #24518)\n - Agents/Reasoning: when model-default thinking is active (for example `thinking=low`), keep auto-reasoning disabled unless explicitly enabled, preventing `Reasoning:` thinking-block leakage in channel replies. (#24335, #24290) thanks @Kay-051.\n - Agents/Reasoning: avoid classifying provider reasoning-required errors as context overflows so these failures no longer trigger compaction-style overflow recovery. (#24593) Thanks @vincentkoc.\n - Agents/Models: codify `agents.defaults.model` / `agents.defaults.imageModel` config-boundary input as `string | {primary,fallbacks}`, split explicit vs effective model resolution, and fix `models status --agent` source attribution so defaults-inherited agents are labeled as `defaults` while runtime selection still honors defaults fallback. (#24210) thanks @bianbiandashen.\ndiff --git a/src/telegram/bot-message-dispatch.test.ts b/src/telegram/bot-message-dispatch.test.ts\nindex 5e080e90eb3c..75a8fb6b9af5 100644\n--- a/src/telegram/bot-message-dispatch.test.ts\n+++ b/src/telegram/bot-message-dispatch.test.ts\n@@ -176,6 +176,15 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     });\n   }\n \n+  function createReasoningStreamContext(): TelegramMessageContext {\n+    loadSessionStore.mockReturnValue({\n+      s1: { reasoningLevel: \"stream\" },\n+    });\n+    return createContext({\n+      ctxPayload: { SessionKey: \"s1\" } as unknown as TelegramMessageContext[\"ctxPayload\"],\n+    });\n+  }\n+\n   it(\"streams drafts in private threads and forwards thread id\", async () => {\n     const draftStream = createDraftStream();\n     createTelegramDraftStream.mockReturnValue(draftStream);\n@@ -772,7 +781,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n       deliverReplies.mockResolvedValue({ delivered: true });\n       editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n-      await dispatchWithContext({ context: createContext(), streamMode });\n+      await dispatchWithContext({ context: createReasoningStreamContext(), streamMode });\n \n       expect(reasoningDraftStream.forceNewMessage).toHaveBeenCalledTimes(1);\n     },\n@@ -809,7 +818,11 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n     const bot = createBot();\n-    await dispatchWithContext({ context: createContext(), streamMode: \"partial\", bot });\n+    await dispatchWithContext({\n+      context: createReasoningStreamContext(),\n+      streamMode: \"partial\",\n+      bot,\n+    });\n \n     expect(reasoningDraftParams?.onSupersededPreview).toBeTypeOf(\"function\");\n     const deleteMessageCalls = (\n@@ -836,13 +849,13 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n       );\n       deliverReplies.mockResolvedValue({ delivered: true });\n \n-      await dispatchWithContext({ context: createContext(), streamMode });\n+      await dispatchWithContext({ context: createReasoningStreamContext(), streamMode });\n \n       expect(reasoningDraftStream.forceNewMessage).not.toHaveBeenCalled();\n     },\n   );\n \n-  it(\"does not finalize preview with reasoning payloads before answer payloads\", async () => {\n+  it(\"suppresses reasoning-only final payloads when reasoning level is off\", async () => {\n     setupDraftStreams({ answerMessageId: 999 });\n     dispatchReplyWithBufferedBlockDispatcher.mockImplementation(\n       async ({ dispatcherOptions, replyOptions }) => {\n@@ -860,14 +873,11 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n \n     await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n \n-    // Keep reasoning as its own message.\n-    expect(deliverReplies).toHaveBeenCalledTimes(1);\n-    expect(deliverReplies).toHaveBeenCalledWith(\n+    expect(deliverReplies).not.toHaveBeenCalledWith(\n       expect.objectContaining({\n         replies: [expect.objectContaining({ text: \"Reasoning:\\n_step one_\" })],\n       }),\n     );\n-    // Finalize preview with the actual answer instead of overwriting with reasoning.\n     expect(editMessageTelegram).toHaveBeenCalledTimes(1);\n     expect(editMessageTelegram).toHaveBeenCalledWith(\n       123,\n@@ -877,6 +887,25 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     );\n   });\n \n+  it(\"does not resend suppressed reasoning-only text through raw fallback\", async () => {\n+    setupDraftStreams({ answerMessageId: 999 });\n+    dispatchReplyWithBufferedBlockDispatcher.mockImplementation(async ({ dispatcherOptions }) => {\n+      await dispatcherOptions.deliver({ text: \"Reasoning:\\n_step one_\" }, { kind: \"final\" });\n+      return { queuedFinal: true };\n+    });\n+    deliverReplies.mockResolvedValue({ delivered: true });\n+    editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n+\n+    await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n+\n+    expect(deliverReplies).not.toHaveBeenCalledWith(\n+      expect.objectContaining({\n+        replies: [expect.objectContaining({ text: \"Reasoning:\\n_step one_\" })],\n+      }),\n+    );\n+    expect(editMessageTelegram).not.toHaveBeenCalled();\n+  });\n+\n   it(\"keeps reasoning and answer streaming in separate preview lanes\", async () => {\n     const { answerDraftStream, reasoningDraftStream } = setupDraftStreams({\n       answerMessageId: 999,\n@@ -893,7 +922,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     deliverReplies.mockResolvedValue({ delivered: true });\n     editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n-    await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n+    await dispatchWithContext({ context: createReasoningStreamContext(), streamMode: \"partial\" });\n \n     expect(reasoningDraftStream.update).toHaveBeenCalledWith(\"Reasoning:\\n_Working on it..._\");\n     expect(answerDraftStream.update).toHaveBeenCalledWith(\"Checking the directory...\");\n@@ -913,7 +942,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     deliverReplies.mockResolvedValue({ delivered: true });\n     editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n-    await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n+    await dispatchWithContext({ context: createReasoningStreamContext(), streamMode: \"partial\" });\n \n     expect(editMessageTelegram).not.toHaveBeenCalled();\n     expect(deliverReplies).toHaveBeenCalledWith(\n@@ -955,7 +984,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n       deliverReplies.mockResolvedValue({ delivered: true });\n       editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"111\" });\n \n-      await dispatchWithContext({ context: createContext(), streamMode });\n+      await dispatchWithContext({ context: createReasoningStreamContext(), streamMode });\n \n       expect(reasoningDraftStream.forceNewMessage).not.toHaveBeenCalled();\n       expect(editMessageTelegram).toHaveBeenCalledWith(\n@@ -990,7 +1019,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     deliverReplies.mockResolvedValue({ delivered: true });\n     editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n-    await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n+    await dispatchWithContext({ context: createReasoningStreamContext(), streamMode: \"partial\" });\n \n     expect(editMessageTelegram).toHaveBeenNthCalledWith(1, 123, 999, \"3\", expect.any(Object));\n     expect(editMessageTelegram).toHaveBeenNthCalledWith(\n@@ -1028,7 +1057,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     deliverReplies.mockResolvedValue({ delivered: true });\n     editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n-    await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n+    await dispatchWithContext({ context: createReasoningStreamContext(), streamMode: \"partial\" });\n \n     expect(reasoningDraftStream.update).toHaveBeenCalledWith(\n       \"Reasoning:\\n_Counting letters in strawberry_\",\n@@ -1060,7 +1089,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     deliverReplies.mockResolvedValue({ delivered: true });\n     editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n-    await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n+    await dispatchWithContext({ context: createReasoningStreamContext(), streamMode: \"partial\" });\n \n     expect(reasoningDraftStream.update).toHaveBeenCalledWith(\n       \"Reasoning:\\n_Counting letters in strawberry_\",\n@@ -1096,7 +1125,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     deliverReplies.mockResolvedValue({ delivered: true });\n     editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n-    await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n+    await dispatchWithContext({ context: createReasoningStreamContext(), streamMode: \"partial\" });\n \n     expect(reasoningDraftStream.update).toHaveBeenCalledWith(\n       \"Reasoning:\\n_Word: strawberry. r appears at 3, 8, 9._\",\n@@ -1127,7 +1156,7 @@ describe(\"dispatchTelegramMessage draft streaming\", () => {\n     deliverReplies.mockResolvedValue({ delivered: true });\n     editMessageTelegram.mockResolvedValue({ ok: true, chatId: \"123\", messageId: \"999\" });\n \n-    await dispatchWithContext({ context: createContext(), streamMode: \"partial\" });\n+    await dispatchWithContext({ context: createReasoningStreamContext(), streamMode: \"partial\" });\n \n     expect(editMessageTelegram).toHaveBeenNthCalledWith(\n       1,\ndiff --git a/src/telegram/bot-message-dispatch.ts b/src/telegram/bot-message-dispatch.ts\nindex 443555fdd731..7dd0c48450ac 100644\n--- a/src/telegram/bot-message-dispatch.ts\n+++ b/src/telegram/bot-message-dispatch.ts\n@@ -202,16 +202,25 @@ export const dispatchTelegramMessage = async ({\n   let splitReasoningOnNextStream = false;\n   const reasoningStepState = createTelegramReasoningStepState();\n   type SplitLaneSegment = { lane: LaneName; text: string };\n-  const splitTextIntoLaneSegments = (text?: string): SplitLaneSegment[] => {\n+  type SplitLaneSegmentsResult = {\n+    segments: SplitLaneSegment[];\n+    suppressedReasoningOnly: boolean;\n+  };\n+  const splitTextIntoLaneSegments = (text?: string): SplitLaneSegmentsResult => {\n     const split = splitTelegramReasoningText(text);\n     const segments: SplitLaneSegment[] = [];\n-    if (split.reasoningText) {\n+    const suppressReasoning = resolvedReasoningLevel === \"off\";\n+    if (split.reasoningText && !suppressReasoning) {\n       segments.push({ lane: \"reasoning\", text: split.reasoningText });\n     }\n     if (split.answerText) {\n       segments.push({ lane: \"answer\", text: split.answerText });\n     }\n-    return segments;\n+    return {\n+      segments,\n+      suppressedReasoningOnly:\n+        Boolean(split.reasoningText) && suppressReasoning && !split.answerText,\n+    };\n   };\n   const resetDraftLaneState = (lane: DraftLaneState) => {\n     lane.lastPartialText = \"\";\n@@ -241,7 +250,8 @@ export const dispatchTelegramMessage = async ({\n     laneStream.update(text);\n   };\n   const ingestDraftLaneSegments = (text: string | undefined) => {\n-    for (const segment of splitTextIntoLaneSegments(text)) {\n+    const split = splitTextIntoLaneSegments(text);\n+    for (const segment of split.segments) {\n       if (segment.lane === \"reasoning\") {\n         reasoningStepState.noteReasoningHint();\n         reasoningStepState.noteReasoningDelivered();\n@@ -418,7 +428,8 @@ export const dispatchTelegramMessage = async ({\n           const previewButtons = (\n             payload.channelData?.telegram as { buttons?: TelegramInlineButtons } | undefined\n           )?.buttons;\n-          const segments = splitTextIntoLaneSegments(payload.text);\n+          const split = splitTextIntoLaneSegments(payload.text);\n+          const segments = split.segments;\n           const hasMedia = Boolean(payload.mediaUrl) || (payload.mediaUrls?.length ?? 0) > 0;\n \n           const flushBufferedFinalAnswer = async () => {\n@@ -478,6 +489,17 @@ export const dispatchTelegramMessage = async ({\n           if (segments.length > 0) {\n             return;\n           }\n+          if (split.suppressedReasoningOnly) {\n+            if (hasMedia) {\n+              const payloadWithoutSuppressedReasoning =\n+                typeof payload.text === \"string\" ? { ...payload, text: \"\" } : payload;\n+              await sendPayload(payloadWithoutSuppressedReasoning);\n+            }\n+            if (info.kind === \"final\") {\n+              await flushBufferedFinalAnswer();\n+            }\n+            return;\n+          }\n \n           if (info.kind === \"final\") {\n             await answerLane.stream?.stop();\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "fix(telegram): suppress reasoning-only delivery segments when reasoning level is off",
					"latencyMs": 2924,
					"costUsd": 0.02344,
					"inputTokens": 4598,
					"outputTokens": 18,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 4598,
								"output_tokens": 18,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 3984.189456,
										"endTime": 6562.283934,
										"statusCode": 200,
										"providerResponseId": "msg_0149uWH6Bze95pqASEg4vQ3o"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.02344",
							"generationId": "gen_01KJ6F4MZ1A7PAYC6Z2RQ9T79A",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "fix(telegram): suppress reasoning-only segments and block raw fallback resend when reasoning is off",
					"latencyMs": 1873,
					"costUsd": 0.014142,
					"inputTokens": 4599,
					"outputTokens": 23,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 4599,
								"output_tokens": 23,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 49107.658971,
										"endTime": 50644.979246,
										"statusCode": 200,
										"providerResponseId": "msg_01Xspk3ZPNXQDcEqvn9eHVpr"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.014142",
							"generationId": "gen_01KJ6F4PSHNHE5MM8RJG68VPTF",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(telegram): suppress reasoning-only delivery segments when reasoning level is off",
					"latencyMs": 847,
					"costUsd": 0.0003525,
					"inputTokens": 3510,
					"outputTokens": 15,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 501565.823434,
										"endTime": 502039.747812,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0003525",
							"marketCost": "0.0003525",
							"generationId": "gen_01KJ6F4M4AK9N1EW8B4M0T94BW",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "fix(",
					"latencyMs": 3674,
					"costUsd": 0.00957,
					"inputTokens": 4089,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 114,
								"promptTokenCount": 4089,
								"candidatesTokenCount": 2,
								"totalTokenCount": 4205,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 50152.388193,
										"endTime": 53473.573366,
										"statusCode": 200,
										"providerResponseId": "FOqcadnXHKzCotkPt9XyuQM"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00957",
							"generationId": "gen_01KJ6F4QTDHEZ7KQ4KBV08T0CT",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "feat(telegram): suppress reasoning-only delivery segments when reasoning is off",
					"latencyMs": 721,
					"costUsd": 0.001206,
					"inputTokens": 3975,
					"outputTokens": 15,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 8875.236362,
										"endTime": 9258.458704,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.001206",
							"marketCost": "0.001206",
							"generationId": "gen_01KJ6F4RM0GD3Y1Y1RFDNA2AJN",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "feat(telegram): suppress reasoning-only text when `/reasoning off` is active",
					"latencyMs": 684,
					"costUsd": 0.00015972,
					"inputTokens": 3975,
					"outputTokens": 18,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 1189078.737241,
										"endTime": 1189421.658438,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00015972",
							"marketCost": "0.00015972",
							"generationId": "gen_01KJ6F4M4ZNBHWXEJ419370R7E",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "fix(telegram): suppress reasoning-only segments and prevent raw fallback resend",
					"latencyMs": 2046,
					"costUsd": 0.0064925,
					"inputTokens": 3574,
					"outputTokens": 17,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_068c67a4dc5254e200699cea11d518819cacd189a41e0ad58c",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 47340.140268,
										"endTime": 49051.101287,
										"statusCode": 200,
										"providerResponseId": "resp_068c67a4dc5254e200699cea11d518819cacd189a41e0ad58c"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.0064925",
							"generationId": "gen_01KJ6F4MSGE8339YGWSYS54742",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "feat(telegram): suppress reasoning-only delivery when reasoning level is off",
					"latencyMs": 11323,
					"costUsd": 0.00108568,
					"inputTokens": 3749,
					"outputTokens": 270,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 46379.719011,
										"endTime": 57362.575077,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00108568",
							"marketCost": "0.00108568",
							"generationId": "gen_01KJ6F4M48FC9639CHTPMQ2CSK",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "rails-12e24eaf-introduce-in-this-week-in-this-mo",
			"title": "Introduce `in_this_week?`, `in_this_month?`, and `in_this_year?` to Date/Time (#55770)",
			"sourceRepo": "rails/rails",
			"sourceCommitUrl": "https://github.com/rails/rails/commit/12e24eaf2f0a9613e015653f013dd131317d9bf5",
			"diff": "diff --git a/activesupport/CHANGELOG.md b/activesupport/CHANGELOG.md\nindex 94d2ad1bf15c4..fbbbde465945c 100644\n--- a/activesupport/CHANGELOG.md\n+++ b/activesupport/CHANGELOG.md\n@@ -1,3 +1,16 @@\n+*   Introduce `this_week?`, `this_month?`, and `this_year?` methods to Date/Time\n+\n+    Similar to `today?`, `tomorrow?`, and `yesterday?`, these methods are useful to\n+    query time instances against the current period.\n+\n+    ```ruby\n+    unless post.created_at.this_week?\n+      link_to \"See week recap\", week_recap_path(date)\n+    end\n+    ```\n+\n+    *Matheus Richard*\n+\n *   Removed the deprecated `ActiveSupport::Multibyte::Chars` class.\n \n     As well as `String#mb_chars`\ndiff --git a/activesupport/lib/active_support/core_ext/date_and_time/calculations.rb b/activesupport/lib/active_support/core_ext/date_and_time/calculations.rb\nindex e713cee1fed96..dd1e3fff4d813 100644\n--- a/activesupport/lib/active_support/core_ext/date_and_time/calculations.rb\n+++ b/activesupport/lib/active_support/core_ext/date_and_time/calculations.rb\n@@ -63,6 +63,21 @@ def on_weekday?\n       !WEEKEND_DAYS.include?(wday)\n     end\n \n+    # Returns true if the date/time falls within the current week.\n+    def this_week?\n+      ::Date.current.all_week.include?(to_date)\n+    end\n+\n+    # Returns true if the date/time falls within the current month.\n+    def this_month?\n+      ::Date.current.all_month.include?(to_date)\n+    end\n+\n+    # Returns true if the date/time falls within the current year.\n+    def this_year?\n+      ::Date.current.all_year.include?(to_date)\n+    end\n+\n     # Returns true if the date/time falls before <tt>date_or_time</tt>.\n     def before?(date_or_time)\n       self < date_or_time\ndiff --git a/activesupport/test/core_ext/date_time_ext_test.rb b/activesupport/test/core_ext/date_time_ext_test.rb\nindex bbff9a515395e..410f29acb06f2 100644\n--- a/activesupport/test/core_ext/date_time_ext_test.rb\n+++ b/activesupport/test/core_ext/date_time_ext_test.rb\n@@ -358,6 +358,33 @@ def test_future_without_offset\n     end\n   end\n \n+  def test_this_week\n+    Date.stub(:current, Date.new(2000, 1, 5)) do # Wed, 2000-01-05\n+      assert_equal false, Time.utc(2000, 1, 2, 23, 59, 59).this_week?\n+      assert_equal true,  Time.utc(2000, 1, 3, 0, 0, 0).this_week?\n+      assert_equal true,  Time.utc(2000, 1, 9, 23, 59, 59).this_week?\n+      assert_equal false, Time.utc(2000, 1, 10, 0, 0, 0).this_week?\n+    end\n+  end\n+\n+  def test_this_month\n+    Date.stub(:current, Date.new(2000, 1, 15)) do\n+      assert_equal false, Time.utc(1999, 12, 31, 23, 59, 59).this_month?\n+      assert_equal true,  Time.utc(2000, 1, 1, 0, 0, 0).this_month?\n+      assert_equal true,  Time.utc(2000, 1, 31, 23, 59, 59).this_month?\n+      assert_equal false, Time.utc(2000, 2, 1, 0, 0, 0).this_month?\n+    end\n+  end\n+\n+  def test_this_year\n+    Date.stub(:current, Date.new(2000, 6, 30)) do\n+      assert_equal false, Time.utc(1999, 12, 31, 23, 59, 59).this_year?\n+      assert_equal true,  Time.utc(2000, 1, 1, 0, 0, 0).this_year?\n+      assert_equal true,  Time.utc(2000, 12, 31, 23, 59, 59).this_year?\n+      assert_equal false, Time.utc(2001, 1, 1, 0, 0, 0).this_year?\n+    end\n+  end\n+\n   def test_current_returns_date_today_when_zone_is_not_set\n     with_env_tz \"US/Eastern\" do\n       Time.stub(:now, Time.local(1999, 12, 31, 23, 59, 59)) do\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "feat(activesupport): add this_week?, this_month?, and this_year? methods to Date/Time",
					"latencyMs": 2211,
					"costUsd": 0.00891,
					"inputTokens": 1637,
					"outputTokens": 29,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 1637,
								"output_tokens": 29,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 15531.476155,
										"endTime": 17556.890504,
										"statusCode": 200,
										"providerResponseId": "msg_01MdgBsTntjAcab7BcSntSMt"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00891",
							"generationId": "gen_01KJ6F4ZSV38C4DA5Y8DGXD3JJ",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "feat(activesupport): add `this_week?`, `this_month?`, and `this_year?` to Date/Time",
					"latencyMs": 1523,
					"costUsd": 0.005424,
					"inputTokens": 1638,
					"outputTokens": 34,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 1638,
								"output_tokens": 34,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 17821.297583,
										"endTime": 19157.693575,
										"statusCode": 200,
										"providerResponseId": "msg_01XkbjZLuwySt7UQe8zQaoiG"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.005424",
							"generationId": "gen_01KJ6F517P1BPS3CZ1JF67N962",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(core): Introduce this_week?, this_month?, and this_year? methods to Date/Time",
					"latencyMs": 779,
					"costUsd": 0.0001273,
					"inputTokens": 1380,
					"outputTokens": 21,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 15593.159057,
										"endTime": 16165.449495,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0001273",
							"marketCost": "0.0001273",
							"generationId": "gen_01KJ6F4Z1Y4ZK6VEQ6CZ256PAD",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "feat(activesupport",
					"latencyMs": 2803,
					"costUsd": 0.00474,
					"inputTokens": 1674,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 112,
								"promptTokenCount": 1674,
								"candidatesTokenCount": 4,
								"totalTokenCount": 1790,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 17404.183344,
										"endTime": 20014.831778,
										"statusCode": 200,
										"providerResponseId": "HuqcabScMcC28eEPsLG5mQs"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00474",
							"generationId": "gen_01KJ6F51YYRF0NGGSKN9DJC94V",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "feat(core): add this_week?, this_month?, and this_year? methods to Date/Time",
					"latencyMs": 564,
					"costUsd": 0.0004731,
					"inputTokens": 1514,
					"outputTokens": 21,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 18795.629732,
										"endTime": 19128.684958,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0004731",
							"marketCost": "0.0004731",
							"generationId": "gen_01KJ6F52QJNB9K6A2WER36ZWTF",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "feat(active_support): add this_week?, this_month?, this_year? date/time methods",
					"latencyMs": 486,
					"costUsd": 0.00006132,
					"inputTokens": 1514,
					"outputTokens": 19,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 14770.586128,
										"endTime": 15049.273104,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00006132",
							"marketCost": "0.00006132",
							"generationId": "gen_01KJ6F4Z1TJNATDRNAVVB9XEYM",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "feat(activesupport): add this_week?, this_month?, and this_year? to Date/Time",
					"latencyMs": 1761,
					"costUsd": 0.002709,
					"inputTokens": 1356,
					"outputTokens": 24,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_051282b08a713f4200699cea1c89e481909c2298198dd04f6b",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 14907.720962,
										"endTime": 16468.58884,
										"statusCode": 200,
										"providerResponseId": "resp_051282b08a713f4200699cea1c89e481909c2298198dd04f6b"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.002709",
							"generationId": "gen_01KJ6F4ZGRGW0B3Y871Q4MXQQ0",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "feat(date_and_time): introduce this_week?, this_month?, and this_year? methods",
					"latencyMs": 11528,
					"costUsd": 0.00080328,
					"inputTokens": 1527,
					"outputTokens": 378,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 13985.146808,
										"endTime": 25302.156238,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00080328",
							"marketCost": "0.00080328",
							"generationId": "gen_01KJ6F4Z2240QFDCAR02MTFPA3",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "rails-752cc391-optimize-calculating-remote-ip-ad",
			"title": "Optimize calculating remote IP address",
			"sourceRepo": "rails/rails",
			"sourceCommitUrl": "https://github.com/rails/rails/commit/752cc3915d8830e09e236308bff8da1282ed4c9c",
			"diff": "diff --git a/actionpack/lib/action_dispatch/middleware/remote_ip.rb b/actionpack/lib/action_dispatch/middleware/remote_ip.rb\nindex c3aaefbd1a2a5..980b9d8d970bf 100644\n--- a/actionpack/lib/action_dispatch/middleware/remote_ip.rb\n+++ b/actionpack/lib/action_dispatch/middleware/remote_ip.rb\n@@ -163,10 +163,11 @@ def calculate_ip\n         #     - REMOTE_ADDR will be the IP that made the request to Rack\n         ips = forwarded_ips + client_ips\n         ips.compact!\n+        ips << remote_addr\n \n         # If every single IP option is in the trusted list, return the IP that's\n         # furthest away\n-        filter_proxies(ips + [remote_addr]).first || ips.last || remote_addr\n+        first_non_proxy(ips) || ips[-2] || ips.last\n       end\n \n       # Memoizes the value returned by #calculate_ip and returns it for\n@@ -194,9 +195,18 @@ def sanitize_ips(ips) # :doc:\n         ips\n       end\n \n-      def filter_proxies(ips) # :doc:\n-        ips.reject do |ip|\n-          @proxies.any? { |proxy| proxy === ip }\n+      def first_non_proxy(ips) # :doc:\n+        ips.find do |raw_ip|\n+          return unless raw_ip\n+\n+          ip = IPAddr.new(raw_ip)\n+          @proxies.none? do |proxy|\n+            if proxy.is_a?(IPAddr)\n+              proxy.include?(ip)\n+            else\n+              proxy === raw_ip\n+            end\n+          end\n         end\n       end\n     end\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "fix(actiondispatch): correct remote IP filtering to properly match IPAddr proxies",
					"latencyMs": 2792,
					"costUsd": 0.004115,
					"inputTokens": 718,
					"outputTokens": 21,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 718,
								"output_tokens": 21,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 17823.019842,
										"endTime": 20368.102868,
										"statusCode": 200,
										"providerResponseId": "msg_01TuoW4vvTa1bMNranDcGa5N"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.004115",
							"generationId": "gen_01KJ6F5ARXY9THMJA40VEBHSMD",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "fix(remote_ip): use first_non_proxy with IPAddr include check and fix fallback IP logic",
					"latencyMs": 1822,
					"costUsd": 0.002547,
					"inputTokens": 719,
					"outputTokens": 26,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 719,
								"output_tokens": 26,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 71132.705784,
										"endTime": 72772.058989,
										"statusCode": 200,
										"providerResponseId": "msg_01CJeB5wJMoGF8B4zVswEhBu"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.002547",
							"generationId": "gen_01KJ6F5C1EVP0FTVF2VX3HR2VD",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(action_dispatch): update remote_ip calculation to include remote_addr.",
					"latencyMs": 440,
					"costUsd": 0.0000631,
					"inputTokens": 617,
					"outputTokens": 14,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 69372.810735,
										"endTime": 69608.629513,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0000631",
							"marketCost": "0.0000631",
							"generationId": "gen_01KJ6F5AA9BQGXCD41V8FSRJWT",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "fix(action",
					"latencyMs": 3205,
					"costUsd": 0.002766,
					"inputTokens": 687,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 113,
								"promptTokenCount": 687,
								"candidatesTokenCount": 3,
								"totalTokenCount": 803,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 29198.424705,
										"endTime": 32184.831333,
										"statusCode": 200,
										"providerResponseId": "Kuqcad-TLeudwu8PhNPHwA4"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.002766",
							"generationId": "gen_01KJ6F5DFWJ2M03AVCTVPKJFTC",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "fix(core): update remote IP calculation logic",
					"latencyMs": 504,
					"costUsd": 0.0001995,
					"inputTokens": 635,
					"outputTokens": 10,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 30160.891408,
										"endTime": 30475.835022,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0001995",
							"marketCost": "0.0001995",
							"generationId": "gen_01KJ6F5DTD6VRDE9604GW01WXW",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "fix(action_dispatch): update proxy IP resolution logic",
					"latencyMs": 455,
					"costUsd": 0.00002584,
					"inputTokens": 635,
					"outputTokens": 11,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 26771.903272,
										"endTime": 27037.137268,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00002584",
							"marketCost": "0.00002584",
							"generationId": "gen_01KJ6F5A9WWHMTQJB65ZKWA7T7",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "fix(actionpack): correctly detect first non-proxy IP with IPAddr proxies",
					"latencyMs": 1341,
					"costUsd": 0.00130025,
					"inputTokens": 591,
					"outputTokens": 19,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_03d9c97db3281e0300699cea27e630819f9fdbcc07f01b4f11",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 27319.473442,
										"endTime": 28313.856286,
										"statusCode": 200,
										"providerResponseId": "resp_03d9c97db3281e0300699cea27e630819f9fdbcc07f01b4f11"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00130025",
							"generationId": "gen_01KJ6F5AW4ZX5A8W9YJ5MVC1D0",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "refactor(remote_ip): rename filter_proxies to first_non_proxy and update IP calculation logic",
					"latencyMs": 11743,
					"costUsd": 0.00086224,
					"inputTokens": 779,
					"outputTokens": 494,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 26980.849178,
										"endTime": 38531.979987,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00086224",
							"marketCost": "0.00086224",
							"generationId": "gen_01KJ6F5AA29YD2NWS3HAQ804B2",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "ai-4c3a932a-fix-devtools-use-explicit-env-flag-f",
			"title": "fix(devtools): use explicit env flag for dev mode detection (#12694)",
			"sourceRepo": "vercel/ai",
			"sourceCommitUrl": "https://github.com/vercel/ai/commit/4c3a932a54db2dbb1c35f419e04720db609ad858",
			"diff": "diff --git a/.changeset/cuddly-turtles-collect.md b/.changeset/cuddly-turtles-collect.md\nnew file mode 100644\nindex 000000000000..d055d705000e\n--- /dev/null\n+++ b/.changeset/cuddly-turtles-collect.md\n@@ -0,0 +1,5 @@\n+---\n+'@ai-sdk/devtools': patch\n+---\n+\n+Use explicit AI_SDK_DEVTOOLS_DEV env flag for dev mode detection\ndiff --git a/packages/devtools/package.json b/packages/devtools/package.json\nindex 27ad479ca540..71e03aae5ae1 100644\n--- a/packages/devtools/package.json\n+++ b/packages/devtools/package.json\n@@ -26,7 +26,7 @@\n   ],\n   \"scripts\": {\n     \"dev\": \"concurrently -k \\\"pnpm dev:api\\\" \\\"pnpm dev:client\\\"\",\n-    \"dev:api\": \"tsx src/viewer/server.ts\",\n+    \"dev:api\": \"AI_SDK_DEVTOOLS_DEV=true tsx src/viewer/server.ts\",\n     \"dev:client\": \"vite\",\n     \"example\": \"tsx examples/basic/index.ts\",\n     \"start\": \"node dist/viewer/server.js\",\ndiff --git a/packages/devtools/src/viewer/server.ts b/packages/devtools/src/viewer/server.ts\nindex 111026e6578a..8c26c4cc70ab 100644\n--- a/packages/devtools/src/viewer/server.ts\n+++ b/packages/devtools/src/viewer/server.ts\n@@ -36,13 +36,19 @@ const broadcastToClients = (event: string, data: Record<string, unknown>) => {\n \n const __dirname = path.dirname(fileURLToPath(import.meta.url));\n \n-// Determine if we're running from source (tsx) or built (dist)\n-// We're in dev mode if NOT running from the dist folder\n-const isDevMode =\n-  !__dirname.includes('/dist/') || process.env.NODE_ENV === 'development';\n-const projectRoot = isDevMode\n-  ? path.resolve(__dirname, '../..')\n-  : path.resolve(__dirname, '../..');\n+// Determine whether to use the dev-mode Vite proxy or serve the built client.\n+//\n+// We rely exclusively on an explicit env flag to avoid false positives in\n+// monorepos where /dist paths are common.\n+//\n+//   AI_SDK_DEVTOOLS_DEV=true  → use dev mode (Vite proxy)\n+//   AI_SDK_DEVTOOLS_DEV=false → use production mode (serve built client)\n+//\n+// If the flag is unset, default to production mode.\n+const devEnv = process.env.AI_SDK_DEVTOOLS_DEV;\n+const isDevMode = devEnv !== undefined && devEnv !== 'false' && devEnv !== '0';\n+// __dirname points at packages/devtools/src/viewer, so ../.. is the package root.\n+const projectRoot = path.resolve(__dirname, '../..');\n \n // Client directory: dist/client in both cases\n const clientDir = path.join(projectRoot, 'dist/client');\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "fix(devtools): use explicit AI_SDK_DEVTOOLS_DEV env flag for dev mode detection",
					"latencyMs": 1995,
					"costUsd": 0.006085,
					"inputTokens": 1087,
					"outputTokens": 26,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 1087,
								"output_tokens": 26,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 39441.334508,
										"endTime": 41237.913256,
										"statusCode": 200,
										"providerResponseId": "msg_01QnHsPMGSiF23gan3w1QooD"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.006085",
							"generationId": "gen_01KJ6F5P8000F18PQ1GKB7VZ5M",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "fix(devtools): use explicit AI_SDK_DEVTOOLS_DEV env flag for dev mode detection",
					"latencyMs": 1327,
					"costUsd": 0.003654,
					"inputTokens": 1088,
					"outputTokens": 26,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 1088,
								"output_tokens": 26,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 40012.297252,
										"endTime": 41115.352175,
										"statusCode": 200,
										"providerResponseId": "msg_018yb3Dv2RShaLaJUznvcnpn"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.003654",
							"generationId": "gen_01KJ6F5R67YCW1ERAR7YVGHMQ7",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(devtools): Use explicit AI_SDK_DEVTOOLS_DEV env flag for dev mode detection",
					"latencyMs": 438,
					"costUsd": 0.0000799,
					"inputTokens": 909,
					"outputTokens": 18,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 37549.520821,
										"endTime": 37791.086853,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0000799",
							"marketCost": "0.0000799",
							"generationId": "gen_01KJ6F5NS261EB6661DS5SHJ71",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "fix(",
					"latencyMs": 3065,
					"costUsd": 0.00349,
					"inputTokens": 1049,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 114,
								"promptTokenCount": 1049,
								"candidatesTokenCount": 2,
								"totalTokenCount": 1165,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 41041.913933,
										"endTime": 43903.451189,
										"statusCode": 200,
										"providerResponseId": "Neqcabr2Neudwu8PhNPHwA4"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00349",
							"generationId": "gen_01KJ6F5RG2N8STCJ7N8FHAGREC",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "feat(devtools): use explicit env flag for dev mode detection",
					"latencyMs": 493,
					"costUsd": 0.0002994,
					"inputTokens": 959,
					"outputTokens": 13,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 41330.880325,
										"endTime": 41637.138442,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0002994",
							"marketCost": "0.0002994",
							"generationId": "gen_01KJ6F5SFQC57FXCTSF8TM20DA",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "feat(devtools): add explicit dev mode env flag for Vite proxy detection",
					"latencyMs": 481,
					"costUsd": 0.000039,
					"inputTokens": 959,
					"outputTokens": 16,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 38745.000867,
										"endTime": 39013.605831,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.000039",
							"marketCost": "0.000039",
							"generationId": "gen_01KJ6F5NSPJG5GGPEYBQGDA550",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "fix(devtools): use AI_SDK_DEVTOOLS_DEV env flag for dev mode detection",
					"latencyMs": 2355,
					"costUsd": 0.001848,
					"inputTokens": 888,
					"outputTokens": 21,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_0dddc6819bdf994600699cea33ed5081a0af6ec26be76953cd",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 38125.504657,
										"endTime": 40294.623077,
										"statusCode": 200,
										"providerResponseId": "resp_0dddc6819bdf994600699cea33ed5081a0af6ec26be76953cd"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.001848",
							"generationId": "gen_01KJ6F5P6GPPCN0MWWWP8GM5ZM",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "feat(devtools): use explicit AI_SDK_DEVTOOLS_DEV env flag for dev mode detection",
					"latencyMs": 9039,
					"costUsd": 0.00048414,
					"inputTokens": 1071,
					"outputTokens": 203,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 37696.297211,
										"endTime": 46543.461951,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00048414",
							"marketCost": "0.00048414",
							"generationId": "gen_01KJ6F5NRV496WW0FT13DVAMVC",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "ai-b094c074-fix-anthropic-allow-null-content-in-",
			"title": "fix(anthropic): allow null content in compaction_delta streaming schema (#12471)",
			"sourceRepo": "vercel/ai",
			"sourceCommitUrl": "https://github.com/vercel/ai/commit/b094c0748613f8f25d15ea0ddd1ef5e37a3a15d7",
			"diff": "diff --git a/.changeset/great-grapes-dress.md b/.changeset/great-grapes-dress.md\nnew file mode 100644\nindex 000000000000..24d989da4d1b\n--- /dev/null\n+++ b/.changeset/great-grapes-dress.md\n@@ -0,0 +1,5 @@\n+---\n+'@ai-sdk/anthropic': patch\n+---\n+\n+fix compaction_delta streaming schema to allow null content\ndiff --git a/packages/anthropic/src/anthropic-messages-api.ts b/packages/anthropic/src/anthropic-messages-api.ts\nindex 805f5e6b22b6..e1e825a5be5b 100644\n--- a/packages/anthropic/src/anthropic-messages-api.ts\n+++ b/packages/anthropic/src/anthropic-messages-api.ts\n@@ -1128,7 +1128,7 @@ export const anthropicMessagesChunkSchema = lazySchema(() =>\n           }),\n           z.object({\n             type: z.literal('compaction_delta'),\n-            content: z.string(),\n+            content: z.string().nullish(),\n           }),\n           z.object({\n             type: z.literal('citations_delta'),\ndiff --git a/packages/anthropic/src/anthropic-messages-language-model.test.ts b/packages/anthropic/src/anthropic-messages-language-model.test.ts\nindex 48fd623d2fe0..2528e66871d6 100644\n--- a/packages/anthropic/src/anthropic-messages-language-model.test.ts\n+++ b/packages/anthropic/src/anthropic-messages-language-model.test.ts\n@@ -5679,6 +5679,40 @@ describe('AnthropicMessagesLanguageModel', () => {\n       });\n     });\n \n+    it('should handle compaction_delta with null content', async () => {\n+      server.urls['https://api.anthropic.com/v1/messages'].response = {\n+        type: 'stream-chunks',\n+        chunks: [\n+          `data: {\"type\":\"message_start\",\"message\":{\"id\":\"msg_test\",\"type\":\"message\",\"role\":\"assistant\",\"model\":\"claude-3-haiku-20240307\",\"stop_sequence\":null,\"usage\":{\"input_tokens\":100,\"output_tokens\":0},\"content\":[],\"stop_reason\":null}}\\n\\n`,\n+          `data: {\"type\":\"content_block_start\",\"index\":0,\"content_block\":{\"type\":\"compaction\",\"content\":null}}\\n\\n`,\n+          `data: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"compaction_delta\",\"content\":null}}\\n\\n`,\n+          `data: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"compaction_delta\",\"content\":\"Summary of conversation.\"}}\\n\\n`,\n+          `data: {\"type\":\"content_block_stop\",\"index\":0}\\n\\n`,\n+          `data: {\"type\":\"message_delta\",\"delta\":{\"stop_reason\":\"end_turn\",\"stop_sequence\":null},\"usage\":{\"output_tokens\":10}}\\n\\n`,\n+          `data: {\"type\":\"message_stop\"}\\n\\n`,\n+        ],\n+      };\n+\n+      const { stream } = await model.doStream({\n+        prompt: TEST_PROMPT,\n+      });\n+\n+      const result = await convertReadableStreamToArray(stream);\n+\n+      // No parsing errors should occur (schema must accept null content)\n+      const errors = result.filter(part => part.type === 'error');\n+      expect(errors).toHaveLength(0);\n+\n+      const compactionDeltas = result.filter(\n+        part => part.type === 'text-delta' && part.id === '0',\n+      );\n+      // null content delta should be skipped, only the string delta comes through\n+      expect(compactionDeltas).toHaveLength(1);\n+      expect((compactionDeltas[0] as { delta: string }).delta).toBe(\n+        'Summary of conversation.',\n+      );\n+    });\n+\n     it('should stream tool deltas', async () => {\n       server.urls['https://api.anthropic.com/v1/messages'].response = {\n         type: 'stream-chunks',\ndiff --git a/packages/anthropic/src/anthropic-messages-language-model.ts b/packages/anthropic/src/anthropic-messages-language-model.ts\nindex 549b232d2605..85670bab68da 100644\n--- a/packages/anthropic/src/anthropic-messages-language-model.ts\n+++ b/packages/anthropic/src/anthropic-messages-language-model.ts\n@@ -1840,11 +1840,13 @@ export class AnthropicMessagesLanguageModel implements LanguageModelV3 {\n                 }\n \n                 case 'compaction_delta': {\n-                  controller.enqueue({\n-                    type: 'text-delta',\n-                    id: String(value.index),\n-                    delta: value.delta.content,\n-                  });\n+                  if (value.delta.content != null) {\n+                    controller.enqueue({\n+                      type: 'text-delta',\n+                      id: String(value.index),\n+                      delta: value.delta.content,\n+                    });\n+                  }\n \n                   return;\n                 }\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "fix(anthropic): allow null content in compaction_delta streaming schema",
					"latencyMs": 1917,
					"costUsd": 0.008555,
					"inputTokens": 1621,
					"outputTokens": 18,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 1621,
								"output_tokens": 18,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 47044.512363,
										"endTime": 48626.303035,
										"statusCode": 200,
										"providerResponseId": "msg_018bQ8zyJsa6wQaEZuzhCgEq"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.008555",
							"generationId": "gen_01KJ6F5ZED5NM5D6S738ST5JC2",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "fix(anthropic): allow null content in compaction_delta streaming schema",
					"latencyMs": 1395,
					"costUsd": 0.005136,
					"inputTokens": 1622,
					"outputTokens": 18,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 1622,
								"output_tokens": 18,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 48728.733012,
										"endTime": 49788.27179,
										"statusCode": 200,
										"providerResponseId": "msg_01E7Js3CjGNEmXpZUktG8yPx"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.005136",
							"generationId": "gen_01KJ6F60S0PAMF2X7EQ6QFZD3Y",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(anthropic): allow null content in compaction_delta streaming schema",
					"latencyMs": 720,
					"costUsd": 0.000121,
					"inputTokens": 1323,
					"outputTokens": 15,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 47762.378849,
										"endTime": 48141.73999,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.000121",
							"marketCost": "0.000121",
							"generationId": "gen_01KJ6F5YQZVY53W843CRZD057S",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "fix(anthropic):",
					"latencyMs": 5006,
					"costUsd": 0.004578,
					"inputTokens": 1593,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 111,
								"promptTokenCount": 1593,
								"candidatesTokenCount": 5,
								"totalTokenCount": 1709,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 1264614.559986,
										"endTime": 1269280.556385,
										"statusCode": 200,
										"providerResponseId": "Puqcaa6DOMC28eEPsLG5mQs"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.004578",
							"generationId": "gen_01KJ6F61A6J8T1ZDZ7F912CGXP",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "fix(anthropic): allow null content in compaction_delta streaming schema",
					"latencyMs": 503,
					"costUsd": 0.0004362,
					"inputTokens": 1409,
					"outputTokens": 15,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 50599.740405,
										"endTime": 50910.315227,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0004362",
							"marketCost": "0.0004362",
							"generationId": "gen_01KJ6F62093CS7PNP9JTQCQH7Z",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "fix(anthropic): allow null content in compaction_delta streaming schema",
					"latencyMs": 594,
					"costUsd": 0.00005696,
					"inputTokens": 1409,
					"outputTokens": 15,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 46678.126491,
										"endTime": 46944.973612,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00005696",
							"marketCost": "0.00005696",
							"generationId": "gen_01KJ6F5YQSP81A10Y407VFCWRR",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "fix(anthropic): allow null compaction_delta content in streaming and skip enqueue",
					"latencyMs": 1494,
					"costUsd": 0.00257425,
					"inputTokens": 1311,
					"outputTokens": 20,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_0be08dcdf0b1974700699cea3ccd9881979885e1235525cdd7",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 48285.375707,
										"endTime": 49447.481022,
										"statusCode": 200,
										"providerResponseId": "resp_0be08dcdf0b1974700699cea3ccd9881979885e1235525cdd7"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00257425",
							"generationId": "gen_01KJ6F5ZA9KYJB6M6DNARMAVGR",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "fix(anthropic): fix compaction_delta streaming schema to allow null content",
					"latencyMs": 9171,
					"costUsd": 0.00064938,
					"inputTokens": 1485,
					"outputTokens": 281,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 47939.989101,
										"endTime": 56769.854333,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00064938",
							"marketCost": "0.00064938",
							"generationId": "gen_01KJ6F5YQYGEB2NQEGM9TWM6GK",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "next-js-aa6d7c22-devtools-omit-empty-looking-err",
			"title": "[devtools] Omit empty looking error messages (#90256)",
			"sourceRepo": "vercel/next.js",
			"sourceCommitUrl": "https://github.com/vercel/next.js/commit/aa6d7c2271092417de894c2d492ea01253b8117f",
			"diff": "diff --git a/packages/next/src/next-devtools/dev-overlay/components/errors/error-message/error-message.tsx b/packages/next/src/next-devtools/dev-overlay/components/errors/error-message/error-message.tsx\nindex f2b98e05cf4e1..92c20dcafeb1d 100644\n--- a/packages/next/src/next-devtools/dev-overlay/components/errors/error-message/error-message.tsx\n+++ b/packages/next/src/next-devtools/dev-overlay/components/errors/error-message/error-message.tsx\n@@ -19,6 +19,10 @@ export function ErrorMessage({ errorMessage, errorType }: ErrorMessageProps) {\n     }\n   }, [errorMessage])\n \n+  if (!errorMessage) {\n+    return null\n+  }\n+\n   // The \"Blocking Route\" error message is specifically formatted to look nice\n   // in the overlay (rather than just passed through from the console), so we\n   // intentionally don't truncate it and rely on the scroll overflow instead.\ndiff --git a/packages/next/src/next-devtools/dev-overlay/container/errors.tsx b/packages/next/src/next-devtools/dev-overlay/container/errors.tsx\nindex 3768e40b061ee..7504d7ff28615 100644\n--- a/packages/next/src/next-devtools/dev-overlay/container/errors.tsx\n+++ b/packages/next/src/next-devtools/dev-overlay/container/errors.tsx\n@@ -55,6 +55,11 @@ function GenericErrorDescription({ error }: { error: Error }) {\n     message = message.slice(envPrefix.length)\n   }\n \n+  message = message.trim()\n+  if (!message) {\n+    return null\n+  }\n+\n   return (\n     <>\n       <HotlinkedText text={message} matcher={matchLinkType} />\ndiff --git a/packages/next/src/next-devtools/dev-overlay/container/runtime-error/error-cause.tsx b/packages/next/src/next-devtools/dev-overlay/container/runtime-error/error-cause.tsx\nindex 64c0ec6542e73..8169c24ca0e5d 100644\n--- a/packages/next/src/next-devtools/dev-overlay/container/runtime-error/error-cause.tsx\n+++ b/packages/next/src/next-devtools/dev-overlay/container/runtime-error/error-cause.tsx\n@@ -11,6 +11,7 @@ type ErrorCauseProps = {\n \n export function ErrorCause({ cause, dialogResizerRef }: ErrorCauseProps) {\n   const frames = React.use(cause.frames())\n+  const trimmedMessage = cause.error.message.trim()\n \n   const firstFrame = useMemo(() => {\n     const index = frames.findIndex(\n@@ -29,7 +30,9 @@ export function ErrorCause({ cause, dialogResizerRef }: ErrorCauseProps) {\n           Caused by: {cause.error.name || 'Error'}\n         </span>\n       </div>\n-      <p className=\"error-cause-message\">{cause.error.message}</p>\n+      {trimmedMessage ? (\n+        <p className=\"error-cause-message\">{trimmedMessage}</p>\n+      ) : null}\n \n       {firstFrame && (\n         <CodeFrame\ndiff --git a/test/e2e/app-dir/instant-validation-causes/instant-validation-causes.test.ts b/test/e2e/app-dir/instant-validation-causes/instant-validation-causes.test.ts\nindex 204bee76ef8c4..6cabdf194cd0e 100644\n--- a/test/e2e/app-dir/instant-validation-causes/instant-validation-causes.test.ts\n+++ b/test/e2e/app-dir/instant-validation-causes/instant-validation-causes.test.ts\n@@ -96,7 +96,6 @@ describe('instant validation causes', () => {\n        \"cause\": [\n          {\n            \"label\": \"Caused by: Instant Validation\",\n-           \"message\": \" \",\n            \"source\": \"app/named-export/page.tsx (3:26) @ unstable_instant\n      > 3 | const unstable_instant = { prefetch: 'static' }\n          |                          ^\",\n@@ -141,7 +140,6 @@ describe('instant validation causes', () => {\n        \"cause\": [\n          {\n            \"label\": \"Caused by: Instant Validation\",\n-           \"message\": \" \",\n            \"source\": \"app/aliased-export/page.tsx (3:17) @ unstable_instant\n      > 3 | const instant = { prefetch: 'static' }\n          |                 ^\",\n@@ -186,7 +184,6 @@ describe('instant validation causes', () => {\n        \"cause\": [\n          {\n            \"label\": \"Caused by: Instant Validation\",\n-           \"message\": \" \",\n            \"source\": \"app/reexport/page.tsx (3:10) @ unstable_instant\n      > 3 | export { unstable_instant } from './config'\n          |          ^\",\n@@ -234,7 +231,6 @@ describe('instant validation causes', () => {\n        \"cause\": [\n          {\n            \"label\": \"Caused by: Instant Validation\",\n-           \"message\": \" \",\n            \"source\": \"app/indirect-export/page.tsx (4:17) @ unstable_instant\n      > 4 | const instant = _instant\n          |                 ^\",\ndiff --git a/test/e2e/app-dir/instant-validation/instant-validation.test.ts b/test/e2e/app-dir/instant-validation/instant-validation.test.ts\nindex 877649192a3ec..aab515d4d4d6d 100644\n--- a/test/e2e/app-dir/instant-validation/instant-validation.test.ts\n+++ b/test/e2e/app-dir/instant-validation/instant-validation.test.ts\n@@ -189,7 +189,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-runtime/page.tsx (3:33) @ unstable_instant\n        > 3 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -234,7 +233,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-dynamic/page.tsx (3:33) @ unstable_instant\n        > 3 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -277,7 +275,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/runtime/missing-suspense-around-dynamic/page.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = {\n            |                                 ^\",\n@@ -322,7 +319,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-dynamic-layout/layout.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -367,7 +363,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/runtime/missing-suspense-around-dynamic-layout/layout.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = {\n            |                                 ^\",\n@@ -411,7 +406,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-params/[param]/page.tsx (1:33) @ unstable_instant\n        > 1 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -465,7 +459,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-search-params/page.tsx (1:33) @ unstable_instant\n        > 1 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -532,7 +525,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/suspense-too-high/page.tsx (3:33) @ unstable_instant\n        > 3 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -577,7 +569,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/runtime/suspense-too-high/page.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = {\n            |                                 ^\",\n@@ -707,7 +698,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/invalid-only-loading-around-dynamic/page.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -759,7 +749,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/blocking-layout/missing-suspense-around-dynamic/page.tsx (3:33) @ unstable_instant\n          > 3 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -818,7 +807,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/invalid-blocking-inside-static/layout.tsx (1:33) @ unstable_instant\n          > 1 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -863,7 +851,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/runtime/invalid-blocking-inside-runtime/layout.tsx (3:33) @ unstable_instant\n          > 3 | export const unstable_instant = {\n              |                                 ^\",\n@@ -909,7 +896,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/missing-suspense-in-parallel-route/page.tsx (3:33) @ unstable_instant\n          > 3 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -955,7 +941,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/missing-suspense-in-parallel-route/foo/page.tsx (1:33) @ unstable_instant\n          > 1 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -1001,7 +986,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/missing-suspense-in-parallel-route/bar/page.tsx (1:33) @ unstable_instant\n          > 1 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -1049,7 +1033,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/invalid-client-data-blocks-validation/page.tsx (1:33) @ unstable_instant\n          > 1 | export const unstable_instant = {\n              |                                 ^\",\ndiff --git a/test/lib/add-redbox-matchers.ts b/test/lib/add-redbox-matchers.ts\nindex eb72703f1827e..700037007e7e9 100644\n--- a/test/lib/add-redbox-matchers.ts\n+++ b/test/lib/add-redbox-matchers.ts\n@@ -75,7 +75,7 @@ interface ErrorSnapshotOptions {\n \n interface SanitizedCauseEntry {\n   label: string | null\n-  message: string | null\n+  message?: string\n   source: string | null\n   stack: string[]\n }\n@@ -83,7 +83,7 @@ interface SanitizedCauseEntry {\n export interface ErrorSnapshot {\n   environmentLabel: string | null\n   label: string | null\n-  description: string | null\n+  description?: string\n   componentStack?: string\n   cause?: SanitizedCauseEntry[]\n   source: string | null\n@@ -239,11 +239,14 @@ async function createErrorSnapshot(\n   const snapshot: ErrorSnapshot = {\n     environmentLabel,\n     label: label ?? '<FIXME-excluded-label>',\n-    description: sanitizedDescription,\n     source: focusedSource,\n     stack: sanitizeStack(stack, next),\n   }\n \n+  if (sanitizedDescription !== null) {\n+    snapshot.description = sanitizedDescription\n+  }\n+\n   // Hydration diffs are only relevant to some specific errors\n   // so we hide them from the snapshots unless they are present.\n   if (componentStack !== null) {\n@@ -252,12 +255,17 @@ async function createErrorSnapshot(\n \n   // Error.cause chain is only relevant when present.\n   if (cause !== null) {\n-    snapshot.cause = cause.map((entry) => ({\n-      label: entry.label,\n-      message: entry.message,\n-      source: focusSource(entry.source, next),\n-      stack: sanitizeStack(entry.stack, next) ?? [],\n-    }))\n+    snapshot.cause = cause.map((entry) => {\n+      const causeEntry: SanitizedCauseEntry = {\n+        label: entry.label,\n+        source: focusSource(entry.source, next),\n+        stack: sanitizeStack(entry.stack, next) ?? [],\n+      }\n+      if (entry.message !== null) {\n+        causeEntry.message = entry.message\n+      }\n+      return causeEntry\n+    })\n   }\n \n   return snapshot\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "fix(next-devtools): hide empty error messages in dev overlay",
					"latencyMs": 2240,
					"costUsd": 0.023185,
					"inputTokens": 4552,
					"outputTokens": 17,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 4552,
								"output_tokens": 17,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 48201.34989,
										"endTime": 50042.265251,
										"statusCode": 200,
										"providerResponseId": "msg_01FhpTjNijUaEvMyrRA8cXf2"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.023185",
							"generationId": "gen_01KJ6F68DSGHY19F8QSYWCNE7M",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "fix(dev-overlay): hide empty or whitespace-only error messages in overlay",
					"latencyMs": 1675,
					"costUsd": 0.013959,
					"inputTokens": 4553,
					"outputTokens": 20,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 4553,
								"output_tokens": 20,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 58334.283557,
										"endTime": 59674.568984,
										"statusCode": 200,
										"providerResponseId": "msg_014pGpNB85MX8qsN3u59tSKa"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.013959",
							"generationId": "gen_01KJ6F69QN75KXD6NAN0P51YTG",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(core): trim error messages",
					"latencyMs": 723,
					"costUsd": 0.00035,
					"inputTokens": 3621,
					"outputTokens": 7,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 1271142.735228,
										"endTime": 1271535.761907,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00035",
							"marketCost": "0.00035",
							"generationId": "gen_01KJ6F67PCXRHW9W57775JX19C",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "fix(",
					"latencyMs": 3470,
					"costUsd": 0.010166,
					"inputTokens": 4387,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 114,
								"promptTokenCount": 4387,
								"candidatesTokenCount": 2,
								"totalTokenCount": 4503,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 58691.001191,
										"endTime": 61768.636379,
										"statusCode": 200,
										"providerResponseId": "SOqcaejIH4mhyOgPvaaUuQ0"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.010166",
							"generationId": "gen_01KJ6F6AKDYTHHXPB91GBMWXK0",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "fix(dev-overlay): add null checks for error messages",
					"latencyMs": 701,
					"costUsd": 0.001173,
					"inputTokens": 3874,
					"outputTokens": 12,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 60146.722689,
										"endTime": 60510.699661,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.001173",
							"marketCost": "0.001173",
							"generationId": "gen_01KJ6F6BC1CSGPT84MSRKKVVA7",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "feat(devtools): sanitize error messages and cause entries to handle empty/null values",
					"latencyMs": 672,
					"costUsd": 0.00015564,
					"inputTokens": 3874,
					"outputTokens": 17,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 56608.37417,
										"endTime": 56952.247518,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00015564",
							"marketCost": "0.00015564",
							"generationId": "gen_01KJ6F67PGTSN8TQHBZRWH0W1J",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "fix(dev-overlay): trim and hide empty error descriptions and cause messages",
					"latencyMs": 1410,
					"costUsd": 0.00658175,
					"inputTokens": 3625,
					"outputTokens": 17,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_0bced980a591786600699cea463308819d9516e200ef19b7c8",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 57311.025814,
										"endTime": 58382.271121,
										"statusCode": 200,
										"providerResponseId": "resp_0bced980a591786600699cea463308819d9516e200ef19b7c8"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00658175",
							"generationId": "gen_01KJ6F68BJ7V0PZKEVNVGHNM3R",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "fix(dev-overlay): trim and hide empty error messages",
					"latencyMs": 11400,
					"costUsd": 0.00112214,
					"inputTokens": 3721,
					"outputTokens": 275,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 55492.207887,
										"endTime": 66560.992259,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.00112214",
							"marketCost": "0.00112214",
							"generationId": "gen_01KJ6F67PHDD3PMXFA9S2FXG8W",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		},
		{
			"id": "zed-9304e02b-agent-allow-the-agent-to-reprompt-a",
			"title": "agent: Allow the agent to reprompt an existing subagent (#49737)",
			"sourceRepo": "zed-industries/zed",
			"sourceCommitUrl": "https://github.com/zed-industries/zed/commit/9304e02b9a2e72169d9082f56fce2c632a02a8eb",
			"diff": "diff --git a/crates/agent/src/agent.rs b/crates/agent/src/agent.rs\nindex 8cea712c19cebb..4e8691c0b5017e 100644\n--- a/crates/agent/src/agent.rs\n+++ b/crates/agent/src/agent.rs\n@@ -1611,11 +1611,60 @@ impl NativeThreadEnvironment {\n             agent.register_session(subagent_thread.clone(), cx)\n         })?;\n \n+        Self::prompt_subagent(\n+            session_id,\n+            subagent_thread,\n+            acp_thread,\n+            parent_thread_entity,\n+            initial_prompt,\n+            timeout,\n+            cx,\n+        )\n+    }\n+\n+    pub(crate) fn resume_subagent_thread(\n+        agent: WeakEntity<NativeAgent>,\n+        parent_thread_entity: Entity<Thread>,\n+        session_id: acp::SessionId,\n+        follow_up_prompt: String,\n+        timeout: Option<Duration>,\n+        cx: &mut App,\n+    ) -> Result<Rc<dyn SubagentHandle>> {\n+        let (subagent_thread, acp_thread) = agent.update(cx, |agent, _cx| {\n+            let session = agent\n+                .sessions\n+                .get(&session_id)\n+                .ok_or_else(|| anyhow!(\"No subagent session found with id {session_id}\"))?;\n+            anyhow::Ok((session.thread.clone(), session.acp_thread.clone()))\n+        })??;\n+\n+        Self::prompt_subagent(\n+            session_id,\n+            subagent_thread,\n+            acp_thread,\n+            parent_thread_entity,\n+            follow_up_prompt,\n+            timeout,\n+            cx,\n+        )\n+    }\n+\n+    fn prompt_subagent(\n+        session_id: acp::SessionId,\n+        subagent_thread: Entity<Thread>,\n+        acp_thread: Entity<acp_thread::AcpThread>,\n+        parent_thread_entity: Entity<Thread>,\n+        prompt: String,\n+        timeout: Option<Duration>,\n+        cx: &mut App,\n+    ) -> Result<Rc<dyn SubagentHandle>> {\n         parent_thread_entity.update(cx, |parent_thread, _cx| {\n             parent_thread.register_running_subagent(subagent_thread.downgrade())\n         });\n \n-        let task = acp_thread.update(cx, |agent, cx| agent.send(vec![initial_prompt.into()], cx));\n+        let task = acp_thread.update(cx, |acp_thread, cx| {\n+            acp_thread.send(vec![prompt.into()], cx)\n+        });\n \n         let timeout_timer = timeout.map(|d| cx.background_executor().timer(d));\n         let wait_for_prompt_to_complete = cx\n@@ -1708,6 +1757,24 @@ impl ThreadEnvironment for NativeThreadEnvironment {\n             cx,\n         )\n     }\n+\n+    fn resume_subagent(\n+        &self,\n+        parent_thread_entity: Entity<Thread>,\n+        session_id: acp::SessionId,\n+        follow_up_prompt: String,\n+        timeout: Option<Duration>,\n+        cx: &mut App,\n+    ) -> Result<Rc<dyn SubagentHandle>> {\n+        Self::resume_subagent_thread(\n+            self.agent.clone(),\n+            parent_thread_entity,\n+            session_id,\n+            follow_up_prompt,\n+            timeout,\n+            cx,\n+        )\n+    }\n }\n \n #[derive(Debug, Clone, Copy)]\n@@ -1737,21 +1804,20 @@ impl SubagentHandle for NativeSubagentHandle {\n         let parent_thread = self.parent_thread.clone();\n \n         cx.spawn(async move |cx| {\n-            match wait_for_prompt.await {\n-                SubagentInitialPromptResult::Completed => {}\n+            let result = match wait_for_prompt.await {\n+                SubagentInitialPromptResult::Completed => thread.read_with(cx, |thread, _cx| {\n+                    thread\n+                        .last_message()\n+                        .map(|m| m.to_markdown())\n+                        .context(\"No response from subagent\")\n+                }),\n                 SubagentInitialPromptResult::Timeout => {\n-                    return Err(anyhow!(\"The time to complete the task was exceeded.\"));\n+                    thread.update(cx, |thread, cx| thread.cancel(cx)).await;\n+                    Err(anyhow!(\"The time to complete the task was exceeded.\"))\n                 }\n-                SubagentInitialPromptResult::Cancelled => return Err(anyhow!(\"User cancelled\")),\n+                SubagentInitialPromptResult::Cancelled => Err(anyhow!(\"User cancelled\")),\n             };\n \n-            let result = thread.read_with(cx, |thread, _cx| {\n-                thread\n-                    .last_message()\n-                    .map(|m| m.to_markdown())\n-                    .context(\"No response from subagent\")\n-            });\n-\n             parent_thread\n                 .update(cx, |parent_thread, cx| {\n                     parent_thread.unregister_running_subagent(&subagent_session_id, cx)\ndiff --git a/crates/agent/src/tests/mod.rs b/crates/agent/src/tests/mod.rs\nindex d895557fc1dec3..2673e33d0e7c8a 100644\n--- a/crates/agent/src/tests/mod.rs\n+++ b/crates/agent/src/tests/mod.rs\n@@ -4233,6 +4233,7 @@ async fn test_subagent_tool_call_end_to_end(cx: &mut TestAppContext) {\n     let subagent_tool_input = SubagentToolInput {\n         label: \"label\".to_string(),\n         task: \"subagent task prompt\".to_string(),\n+        session_id: None,\n         timeout_secs: None,\n     };\n     let subagent_tool_use = LanguageModelToolUse {\n@@ -4383,6 +4384,7 @@ async fn test_subagent_tool_call_cancellation_during_task_prompt(cx: &mut TestAp\n     let subagent_tool_input = SubagentToolInput {\n         label: \"label\".to_string(),\n         task: \"subagent task prompt\".to_string(),\n+        session_id: None,\n         timeout_secs: None,\n     };\n     let subagent_tool_use = LanguageModelToolUse {\n@@ -4460,6 +4462,195 @@ async fn test_subagent_tool_call_cancellation_during_task_prompt(cx: &mut TestAp\n     });\n }\n \n+#[gpui::test]\n+async fn test_subagent_tool_resume_session(cx: &mut TestAppContext) {\n+    init_test(cx);\n+    cx.update(|cx| {\n+        LanguageModelRegistry::test(cx);\n+    });\n+    cx.update(|cx| {\n+        cx.update_flags(true, vec![\"subagents\".to_string()]);\n+    });\n+\n+    let fs = FakeFs::new(cx.executor());\n+    fs.insert_tree(\n+        \"/\",\n+        json!({\n+            \"a\": {\n+                \"b.md\": \"Lorem\"\n+            }\n+        }),\n+    )\n+    .await;\n+    let project = Project::test(fs.clone(), [path!(\"/a\").as_ref()], cx).await;\n+    let thread_store = cx.new(|cx| ThreadStore::new(cx));\n+    let agent = NativeAgent::new(\n+        project.clone(),\n+        thread_store.clone(),\n+        Templates::new(),\n+        None,\n+        fs.clone(),\n+        &mut cx.to_async(),\n+    )\n+    .await\n+    .unwrap();\n+    let connection = Rc::new(NativeAgentConnection(agent.clone()));\n+\n+    let acp_thread = cx\n+        .update(|cx| {\n+            connection\n+                .clone()\n+                .new_session(project.clone(), Path::new(\"\"), cx)\n+        })\n+        .await\n+        .unwrap();\n+    let session_id = acp_thread.read_with(cx, |thread, _| thread.session_id().clone());\n+    let thread = agent.read_with(cx, |agent, _| {\n+        agent.sessions.get(&session_id).unwrap().thread.clone()\n+    });\n+    let model = Arc::new(FakeLanguageModel::default());\n+\n+    thread.update(cx, |thread, cx| {\n+        thread.set_model(model.clone(), cx);\n+    });\n+    cx.run_until_parked();\n+\n+    // === First turn: create subagent ===\n+    let send = acp_thread.update(cx, |thread, cx| thread.send_raw(\"First prompt\", cx));\n+    cx.run_until_parked();\n+    model.send_last_completion_stream_text_chunk(\"spawning subagent\");\n+    let subagent_tool_input = SubagentToolInput {\n+        label: \"initial task\".to_string(),\n+        task: \"do the first task\".to_string(),\n+        session_id: None,\n+        timeout_secs: None,\n+    };\n+    let subagent_tool_use = LanguageModelToolUse {\n+        id: \"subagent_1\".into(),\n+        name: SubagentTool::NAME.into(),\n+        raw_input: serde_json::to_string(&subagent_tool_input).unwrap(),\n+        input: serde_json::to_value(&subagent_tool_input).unwrap(),\n+        is_input_complete: true,\n+        thought_signature: None,\n+    };\n+    model.send_last_completion_stream_event(LanguageModelCompletionEvent::ToolUse(\n+        subagent_tool_use,\n+    ));\n+    model.end_last_completion_stream();\n+\n+    cx.run_until_parked();\n+\n+    let subagent_session_id = thread.read_with(cx, |thread, cx| {\n+        thread\n+            .running_subagent_ids(cx)\n+            .get(0)\n+            .expect(\"subagent thread should be running\")\n+            .clone()\n+    });\n+\n+    let subagent_acp_thread = agent.read_with(cx, |agent, _cx| {\n+        agent\n+            .sessions\n+            .get(&subagent_session_id)\n+            .expect(\"subagent session should exist\")\n+            .acp_thread\n+            .clone()\n+    });\n+\n+    // Subagent responds\n+    model.send_last_completion_stream_text_chunk(\"first task response\");\n+    model.end_last_completion_stream();\n+\n+    cx.run_until_parked();\n+\n+    // Parent model responds to complete first turn\n+    model.send_last_completion_stream_text_chunk(\"First response\");\n+    model.end_last_completion_stream();\n+\n+    send.await.unwrap();\n+\n+    // Verify subagent is no longer running\n+    thread.read_with(cx, |thread, cx| {\n+        assert!(\n+            thread.running_subagent_ids(cx).is_empty(),\n+            \"subagent should not be running after completion\"\n+        );\n+    });\n+\n+    // === Second turn: resume subagent with session_id ===\n+    let send2 = acp_thread.update(cx, |thread, cx| thread.send_raw(\"Follow up\", cx));\n+    cx.run_until_parked();\n+    model.send_last_completion_stream_text_chunk(\"resuming subagent\");\n+    let resume_tool_input = SubagentToolInput {\n+        label: \"follow-up task\".to_string(),\n+        task: \"do the follow-up task\".to_string(),\n+        session_id: Some(subagent_session_id.clone()),\n+        timeout_secs: None,\n+    };\n+    let resume_tool_use = LanguageModelToolUse {\n+        id: \"subagent_2\".into(),\n+        name: SubagentTool::NAME.into(),\n+        raw_input: serde_json::to_string(&resume_tool_input).unwrap(),\n+        input: serde_json::to_value(&resume_tool_input).unwrap(),\n+        is_input_complete: true,\n+        thought_signature: None,\n+    };\n+    model.send_last_completion_stream_event(LanguageModelCompletionEvent::ToolUse(resume_tool_use));\n+    model.end_last_completion_stream();\n+\n+    cx.run_until_parked();\n+\n+    // Subagent should be running again with the same session\n+    thread.read_with(cx, |thread, cx| {\n+        let running = thread.running_subagent_ids(cx);\n+        assert_eq!(running.len(), 1, \"subagent should be running\");\n+        assert_eq!(running[0], subagent_session_id, \"should be same session\");\n+    });\n+\n+    // Subagent responds to follow-up\n+    model.send_last_completion_stream_text_chunk(\"follow-up task response\");\n+    model.end_last_completion_stream();\n+\n+    cx.run_until_parked();\n+\n+    // Parent model responds to complete second turn\n+    model.send_last_completion_stream_text_chunk(\"Second response\");\n+    model.end_last_completion_stream();\n+\n+    send2.await.unwrap();\n+\n+    // Verify subagent is no longer running\n+    thread.read_with(cx, |thread, cx| {\n+        assert!(\n+            thread.running_subagent_ids(cx).is_empty(),\n+            \"subagent should not be running after resume completion\"\n+        );\n+    });\n+\n+    // Verify the subagent's acp thread has both conversation turns\n+    assert_eq!(\n+        subagent_acp_thread.read_with(cx, |thread, cx| thread.to_markdown(cx)),\n+        indoc! {\"\n+            ## User\n+\n+            do the first task\n+\n+            ## Assistant\n+\n+            first task response\n+\n+            ## User\n+\n+            do the follow-up task\n+\n+            ## Assistant\n+\n+            follow-up task response\n+\n+        \"}\n+    );\n+}\n+\n #[gpui::test]\n async fn test_subagent_tool_is_present_when_feature_flag_enabled(cx: &mut TestAppContext) {\n     init_test(cx);\ndiff --git a/crates/agent/src/thread.rs b/crates/agent/src/thread.rs\nindex 93024a97073e6f..cc8a46987d0d01 100644\n--- a/crates/agent/src/thread.rs\n+++ b/crates/agent/src/thread.rs\n@@ -621,6 +621,19 @@ pub trait ThreadEnvironment {\n         timeout: Option<Duration>,\n         cx: &mut App,\n     ) -> Result<Rc<dyn SubagentHandle>>;\n+\n+    fn resume_subagent(\n+        &self,\n+        _parent_thread: Entity<Thread>,\n+        _session_id: acp::SessionId,\n+        _follow_up_prompt: String,\n+        _timeout: Option<Duration>,\n+        _cx: &mut App,\n+    ) -> Result<Rc<dyn SubagentHandle>> {\n+        Err(anyhow::anyhow!(\n+            \"Resuming subagent sessions is not supported\"\n+        ))\n+    }\n }\n \n #[derive(Debug)]\ndiff --git a/crates/agent/src/tools/subagent_tool.rs b/crates/agent/src/tools/subagent_tool.rs\nindex 1c9487dcbe611f..8212192d7bfc51 100644\n--- a/crates/agent/src/tools/subagent_tool.rs\n+++ b/crates/agent/src/tools/subagent_tool.rs\n@@ -23,6 +23,8 @@ use crate::{AgentTool, Thread, ThreadEnvironment, ToolCallEventStream};\n ///\n /// You will receive only the agent's final message as output.\n ///\n+/// If a response (success or error) includes a session_id, you can send a follow-up message to that session by passing the session_id back. This is useful for multi-turn conversations with a subagent, asking clarifying questions about its output, or retrying after timeouts or transient failures.\n+///\n /// Note:\n /// - Agents cannot use tools you don't have access to.\n /// - If spawning multiple agents that might write to the filesystem, provide guidance on how to avoid conflicts (e.g. assign each to different directories).\n@@ -32,6 +34,9 @@ pub struct SubagentToolInput {\n     pub label: String,\n     /// Describe the task for the agent to perform. Be specific about what you want accomplished. Include all necessary context (file paths, requirements, constraints) since the agent cannot see your conversation.\n     pub task: String,\n+    /// Optional session ID of an existing subagent to continue a conversation with. When provided, the task is sent as a follow-up message to that session instead of creating a new one. Use this to ask clarifying questions, request changes based on previous output, or retry after errors.\n+    #[serde(default)]\n+    pub session_id: Option<acp::SessionId>,\n     /// Optional maximum runtime in seconds. The purpose of this timeout is to prevent the agent from getting stuck in infinite loops, NOT to estimate task duration. Be generous if setting. If not set, the agent runs until it completes or is cancelled.\n     #[serde(default)]\n     pub timeout_secs: Option<u64>,\n@@ -45,18 +50,18 @@ pub enum SubagentToolOutput {\n         output: String,\n     },\n     Error {\n+        #[serde(skip_serializing_if = \"Option::is_none\")]\n+        #[serde(default)]\n+        session_id: Option<acp::SessionId>,\n         error: String,\n     },\n }\n \n impl From<SubagentToolOutput> for LanguageModelToolResultContent {\n     fn from(output: SubagentToolOutput) -> Self {\n-        match output {\n-            output @ SubagentToolOutput::Success { .. } => serde_json::to_string(&output)\n-                .unwrap_or_else(|e| format!(\"Failed to serialize subagent output: {e}\"))\n-                .into(),\n-            SubagentToolOutput::Error { error } => error.into(),\n-        }\n+        serde_json::to_string(&output)\n+            .unwrap_or_else(|e| format!(\"Failed to serialize subagent output: {e}\"))\n+            .into()\n     }\n }\n \n@@ -103,25 +108,37 @@ impl AgentTool for SubagentTool {\n     ) -> Task<Result<Self::Output, Self::Output>> {\n         let Some(parent_thread_entity) = self.parent_thread.upgrade() else {\n             return Task::ready(Err(SubagentToolOutput::Error {\n+                session_id: None,\n                 error: \"Parent thread no longer exists\".to_string(),\n             }));\n         };\n \n-        let subagent = match self.environment.create_subagent(\n-            parent_thread_entity,\n-            input.label,\n-            input.task,\n-            input.timeout_secs.map(|secs| Duration::from_secs(secs)),\n-            cx,\n-        ) {\n+        let subagent = if let Some(session_id) = input.session_id {\n+            self.environment.resume_subagent(\n+                parent_thread_entity,\n+                session_id,\n+                input.task,\n+                input.timeout_secs.map(Duration::from_secs),\n+                cx,\n+            )\n+        } else {\n+            self.environment.create_subagent(\n+                parent_thread_entity,\n+                input.label,\n+                input.task,\n+                input.timeout_secs.map(Duration::from_secs),\n+                cx,\n+            )\n+        };\n+        let subagent = match subagent {\n             Ok(subagent) => subagent,\n             Err(err) => {\n                 return Task::ready(Err(SubagentToolOutput::Error {\n+                    session_id: None,\n                     error: err.to_string(),\n                 }));\n             }\n         };\n-\n         let subagent_session_id = subagent.id();\n \n         event_stream.subagent_spawned(subagent_session_id.clone());\n@@ -137,6 +154,7 @@ impl AgentTool for SubagentTool {\n                     .wait_for_output(cx)\n                     .await\n                     .map_err(|e| SubagentToolOutput::Error {\n+                        session_id: Some(subagent_session_id.clone()),\n                         error: e.to_string(),\n                     })?;\n             Ok(SubagentToolOutput::Success {\n@@ -153,17 +171,20 @@ impl AgentTool for SubagentTool {\n         event_stream: ToolCallEventStream,\n         _cx: &mut App,\n     ) -> Result<()> {\n-        match output {\n-            SubagentToolOutput::Success { session_id, .. } => {\n-                event_stream.subagent_spawned(session_id.clone());\n-                let meta = acp::Meta::from_iter([(\n-                    SUBAGENT_SESSION_ID_META_KEY.into(),\n-                    session_id.to_string().into(),\n-                )]);\n-                event_stream.update_fields_with_meta(acp::ToolCallUpdateFields::new(), Some(meta));\n-            }\n-            SubagentToolOutput::Error { .. } => {}\n+        let session_id = match &output {\n+            SubagentToolOutput::Success { session_id, .. } => Some(session_id),\n+            SubagentToolOutput::Error { session_id, .. } => session_id.as_ref(),\n+        };\n+\n+        if let Some(session_id) = session_id {\n+            event_stream.subagent_spawned(session_id.clone());\n+            let meta = acp::Meta::from_iter([(\n+                SUBAGENT_SESSION_ID_META_KEY.into(),\n+                session_id.to_string().into(),\n+            )]);\n+            event_stream.update_fields_with_meta(acp::ToolCallUpdateFields::new(), Some(meta));\n         }\n+\n         Ok(())\n     }\n }\n",
			"results": [
				{
					"modelId": "anthropic/claude-opus-4.5",
					"tier": "frontier",
					"status": "success",
					"message": "feat(agent): add subagent session resumption support",
					"latencyMs": 1734,
					"costUsd": 0.03168,
					"inputTokens": 6261,
					"outputTokens": 15,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 6261,
								"output_tokens": 15,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "not_available"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-opus-4.5",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-opus-4-5-20251101",
								"internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-opus-4.5",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-opus-4-5-20251101",
										"providerApiModelId": "claude-opus-4-5-20251101",
										"credentialType": "byok",
										"success": true,
										"startTime": 68325.640397,
										"endTime": 69716.299475,
										"statusCode": 200,
										"providerResponseId": "msg_01QubYhJdtF8RxweiA74zMFG"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-opus-4.5",
										"canonicalSlug": "anthropic/claude-opus-4.5",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.03168",
							"generationId": "gen_01KJ6F6KPABH8NJAR4Y0YXW4TM",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "anthropic/claude-sonnet-4.6",
					"tier": "frontier",
					"status": "success",
					"message": "feat(agent): add subagent session resumption via session_id in SubagentTool",
					"latencyMs": 1677,
					"costUsd": 0.019146,
					"inputTokens": 6262,
					"outputTokens": 24,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"anthropic": {
							"usage": {
								"input_tokens": 6262,
								"output_tokens": 24,
								"cache_creation_input_tokens": 0,
								"cache_read_input_tokens": 0,
								"cache_creation": {
									"ephemeral_5m_input_tokens": 0,
									"ephemeral_1h_input_tokens": 0
								},
								"service_tier": "standard",
								"inference_geo": "global"
							},
							"cacheCreationInputTokens": 0,
							"stopSequence": null,
							"iterations": null,
							"container": null,
							"contextManagement": null
						},
						"gateway": {
							"routing": {
								"originalModelId": "anthropic/claude-sonnet-4.6",
								"resolvedProvider": "anthropic",
								"resolvedProviderApiModelId": "claude-sonnet-4-6",
								"internalResolvedModelId": "anthropic:claude-sonnet-4-6",
								"fallbacksAvailable": ["vertexAnthropic", "bedrock"],
								"internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
								"planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
								"canonicalSlug": "anthropic/claude-sonnet-4.6",
								"finalProvider": "anthropic",
								"attempts": [
									{
										"provider": "anthropic",
										"internalModelId": "anthropic:claude-sonnet-4-6",
										"providerApiModelId": "claude-sonnet-4-6",
										"credentialType": "byok",
										"success": true,
										"startTime": 70033.876249,
										"endTime": 71373.024377,
										"statusCode": 200,
										"providerResponseId": "msg_012NwguuiriYMq2AMDDfpBj2"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "anthropic/claude-sonnet-4.6",
										"canonicalSlug": "anthropic/claude-sonnet-4.6",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.019146",
							"generationId": "gen_01KJ6F6NC8ZQ1KT4Y214RDP6VJ",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "cerebras/llama3.1-8b",
					"tier": "small",
					"status": "success",
					"message": "feat(cli): add support for resuming subagent sessions",
					"latencyMs": 867,
					"costUsd": 0.0004562,
					"inputTokens": 4678,
					"outputTokens": 12,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"cerebras": {
							"acceptedPredictionTokens": 0,
							"rejectedPredictionTokens": 0
						},
						"gateway": {
							"routing": {
								"originalModelId": "cerebras/llama3.1-8b",
								"resolvedProvider": "cerebras",
								"resolvedProviderApiModelId": "llama3.1-8b",
								"internalResolvedModelId": "cerebras:llama3.1-8b",
								"fallbacksAvailable": [],
								"internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
								"canonicalSlug": "meta/llama-3.1-8b",
								"finalProvider": "cerebras",
								"attempts": [
									{
										"provider": "cerebras",
										"internalModelId": "cerebras:llama3.1-8b",
										"providerApiModelId": "llama3.1-8b",
										"credentialType": "system",
										"success": true,
										"startTime": 68701.534811,
										"endTime": 69218.944544,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "cerebras/llama3.1-8b",
										"canonicalSlug": "cerebras/llama3.1-8b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0004562",
							"marketCost": "0.0004562",
							"generationId": "gen_01KJ6F6JV9596T3PXTGMG1YN3G",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "google/gemini-3-pro-preview",
					"tier": "frontier",
					"status": "success",
					"message": "feat(agent): allow",
					"latencyMs": 3316,
					"costUsd": 0.013182,
					"inputTokens": 5895,
					"outputTokens": 116,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"vertex": {
							"promptFeedback": null,
							"groundingMetadata": null,
							"urlContextMetadata": null,
							"safetyRatings": null,
							"usageMetadata": {
								"thoughtsTokenCount": 111,
								"promptTokenCount": 5895,
								"candidatesTokenCount": 5,
								"totalTokenCount": 6011,
								"trafficType": "ON_DEMAND"
							}
						},
						"gateway": {
							"routing": {
								"originalModelId": "google/gemini-3-pro-preview",
								"resolvedProvider": "vertex",
								"resolvedProviderApiModelId": "gemini-3-pro-preview",
								"internalResolvedModelId": "vertex:gemini-3-pro-preview",
								"fallbacksAvailable": ["google"],
								"internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
								"planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
								"canonicalSlug": "google/gemini-3-pro-preview",
								"finalProvider": "vertex",
								"attempts": [
									{
										"provider": "vertex",
										"internalModelId": "vertex:gemini-3-pro-preview",
										"providerApiModelId": "gemini-3-pro-preview",
										"credentialType": "byok",
										"success": true,
										"startTime": 72989.557974,
										"endTime": 75972.444125,
										"statusCode": 200,
										"providerResponseId": "Veqcab_HB5eiptQPzN-AoQY"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "google/gemini-3-pro-preview",
										"canonicalSlug": "google/gemini-3-pro-preview",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.013182",
							"generationId": "gen_01KJ6F6Q0PPXQT225CE2W9DW00",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/codestral",
					"tier": "small",
					"status": "success",
					"message": "feat(agent): add support for resuming subagent sessions",
					"latencyMs": 711,
					"costUsd": 0.0015096,
					"inputTokens": 4993,
					"outputTokens": 13,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/codestral",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "codestral-latest",
								"internalResolvedModelId": "mistral:codestral-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/codestral",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:codestral-latest",
										"providerApiModelId": "codestral-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 73547.859392,
										"endTime": 73928.578411,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/codestral",
										"canonicalSlug": "mistral/codestral",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0015096",
							"marketCost": "0.0015096",
							"generationId": "gen_01KJ6F6QXZK8W7CTWNJ9FY2DXF",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "mistral/ministral-3b",
					"tier": "small",
					"status": "success",
					"message": "feat(agent): add session-based subagent resume functionality",
					"latencyMs": 652,
					"costUsd": 0.0002002,
					"inputTokens": 4993,
					"outputTokens": 12,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "mistral/ministral-3b",
								"resolvedProvider": "mistral",
								"resolvedProviderApiModelId": "ministral-3b-latest",
								"internalResolvedModelId": "mistral:ministral-3b-latest",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
								"canonicalSlug": "mistral/ministral-3b",
								"finalProvider": "mistral",
								"attempts": [
									{
										"provider": "mistral",
										"internalModelId": "mistral:ministral-3b-latest",
										"providerApiModelId": "ministral-3b-latest",
										"credentialType": "system",
										"success": true,
										"startTime": 68514.599522,
										"endTime": 68828.662611,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "mistral/ministral-3b",
										"canonicalSlug": "mistral/ministral-3b",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0002002",
							"marketCost": "0.0002002",
							"generationId": "gen_01KJ6F6JV0FR0FNCVJAG6PCG03",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "openai/gpt-5.2",
					"tier": "frontier",
					"status": "success",
					"message": "feat(agent): add subagent session resume support to SubagentTool",
					"latencyMs": 4569,
					"costUsd": 0.00841225,
					"inputTokens": 4671,
					"outputTokens": 17,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"openai": {
							"responseId": "resp_0499790c3629aecf00699cea51f1fc81908a994d63eaf1cef6",
							"serviceTier": "default"
						},
						"gateway": {
							"routing": {
								"originalModelId": "openai/gpt-5.2",
								"resolvedProvider": "openai",
								"resolvedProviderApiModelId": "gpt-5.2",
								"internalResolvedModelId": "openai:gpt-5.2",
								"fallbacksAvailable": ["azure"],
								"internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
								"planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
								"canonicalSlug": "openai/gpt-5.2",
								"finalProvider": "openai",
								"attempts": [
									{
										"provider": "openai",
										"internalModelId": "openai:gpt-5.2",
										"providerApiModelId": "gpt-5.2",
										"credentialType": "byok",
										"success": true,
										"startTime": 67933.568445,
										"endTime": 72175.137974,
										"statusCode": 200,
										"providerResponseId": "resp_0499790c3629aecf00699cea51f1fc81908a994d63eaf1cef6"
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "openai/gpt-5.2",
										"canonicalSlug": "openai/gpt-5.2",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0",
							"marketCost": "0.00841225",
							"generationId": "gen_01KJ6F6KF6F066QGQQEGNSHKGE",
							"billableWebSearchCalls": 0
						}
					}
				},
				{
					"modelId": "xai/grok-code-fast-1",
					"tier": "small",
					"status": "success",
					"message": "feat(agent): add support for resuming subagent sessions with session_id",
					"latencyMs": 15249,
					"costUsd": 0.0006572,
					"inputTokens": 4831,
					"outputTokens": 370,
					"humanReview": {
						"overallScore": 3,
						"notes": "Pending manual review.",
						"winnerFlag": false
					},
					"providerMetadata": {
						"gateway": {
							"routing": {
								"originalModelId": "xai/grok-code-fast-1",
								"resolvedProvider": "xai",
								"resolvedProviderApiModelId": "grok-code-fast-1",
								"internalResolvedModelId": "xai:grok-code-fast-1",
								"fallbacksAvailable": [],
								"internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
								"planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
								"canonicalSlug": "xai/grok-code-fast-1",
								"finalProvider": "xai",
								"attempts": [
									{
										"provider": "xai",
										"internalModelId": "xai:grok-code-fast-1",
										"providerApiModelId": "grok-code-fast-1",
										"credentialType": "system",
										"success": true,
										"startTime": 68710.518629,
										"endTime": 83625.671862,
										"statusCode": 200
									}
								],
								"modelAttemptCount": 1,
								"modelAttempts": [
									{
										"modelId": "xai/grok-code-fast-1",
										"canonicalSlug": "xai/grok-code-fast-1",
										"success": false,
										"providerAttemptCount": 0,
										"providerAttempts": []
									}
								],
								"totalProviderAttemptCount": 0
							},
							"cost": "0.0006572",
							"marketCost": "0.0006572",
							"generationId": "gen_01KJ6F6JV0XEQWVJMBQ1V7J00G",
							"billableWebSearchCalls": 0
						}
					}
				}
			]
		}
	],
	"aggregate": {
		"byModel": [
			{
				"modelId": "mistral/ministral-3b",
				"tier": "small",
				"successCount": 10,
				"errorCount": 0,
				"avgLatencyMs": 606,
				"avgCostUsd": 0.0001047,
				"avgScore": 3
			},
			{
				"modelId": "xai/grok-code-fast-1",
				"tier": "small",
				"successCount": 10,
				"errorCount": 0,
				"avgLatencyMs": 11438.8,
				"avgCostUsd": 0.0008613,
				"avgScore": 3
			},
			{
				"modelId": "cerebras/llama3.1-8b",
				"tier": "small",
				"successCount": 10,
				"errorCount": 0,
				"avgLatencyMs": 736.6,
				"avgCostUsd": 0.0002346,
				"avgScore": 3
			},
			{
				"modelId": "openai/gpt-5.2",
				"tier": "frontier",
				"successCount": 10,
				"errorCount": 0,
				"avgLatencyMs": 2099.4,
				"avgCostUsd": 0.004462,
				"avgScore": 3
			},
			{
				"modelId": "anthropic/claude-opus-4.5",
				"tier": "frontier",
				"successCount": 10,
				"errorCount": 0,
				"avgLatencyMs": 2220.9,
				"avgCostUsd": 0.015725,
				"avgScore": 3
			},
			{
				"modelId": "anthropic/claude-sonnet-4.6",
				"tier": "frontier",
				"successCount": 10,
				"errorCount": 0,
				"avgLatencyMs": 1641.7,
				"avgCostUsd": 0.0094965,
				"avgScore": 3
			},
			{
				"modelId": "google/gemini-3-pro-preview",
				"tier": "frontier",
				"successCount": 10,
				"errorCount": 0,
				"avgLatencyMs": 3488.2,
				"avgCostUsd": 0.0071608,
				"avgScore": 3
			},
			{
				"modelId": "mistral/codestral",
				"tier": "small",
				"successCount": 10,
				"errorCount": 0,
				"avgLatencyMs": 652.5,
				"avgCostUsd": 0.0007927,
				"avgScore": 3
			}
		],
		"smallTopModelId": "mistral/ministral-3b",
		"frontierTopModelId": "anthropic/claude-sonnet-4.6"
	}
}
