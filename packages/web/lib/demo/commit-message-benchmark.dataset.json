{
  "generatedAt": "2026-02-23T22:23:00.555Z",
  "provider": "vercel-ai-gateway",
  "models": [
    {
      "id": "mistral/ministral-3b",
      "tier": "small",
      "label": "Ministral 3B"
    },
    {
      "id": "xai/grok-code-fast-1",
      "tier": "small",
      "label": "Grok Code Fast"
    },
    {
      "id": "cerebras/llama3.1-8b",
      "tier": "small",
      "label": "Llama 3.1 8B"
    },
    {
      "id": "openai/gpt-5.2",
      "tier": "frontier",
      "label": "GPT-5.2"
    },
    {
      "id": "anthropic/claude-opus-4.5",
      "tier": "frontier",
      "label": "Claude Opus 4.5"
    },
    {
      "id": "anthropic/claude-sonnet-4.6",
      "tier": "frontier",
      "label": "Claude Sonnet 4.6"
    },
    {
      "id": "google/gemini-3-pro-preview",
      "tier": "frontier",
      "label": "Gemini 3 Pro"
    },
    {
      "id": "mistral/codestral",
      "tier": "small",
      "label": "Codestral"
    }
  ],
  "scenarios": [
    {
      "id": "next-js-aa6d7c22-devtools-omit-empty-looking-err",
      "title": "[devtools] Omit empty looking error messages (#90256)",
      "sourceRepo": "vercel/next.js",
      "sourceCommitUrl": "https://github.com/vercel/next.js/commit/aa6d7c2271092417de894c2d492ea01253b8117f",
      "diff": "diff --git a/packages/next/src/next-devtools/dev-overlay/components/errors/error-message/error-message.tsx b/packages/next/src/next-devtools/dev-overlay/components/errors/error-message/error-message.tsx\nindex f2b98e05cf4e1..92c20dcafeb1d 100644\n--- a/packages/next/src/next-devtools/dev-overlay/components/errors/error-message/error-message.tsx\n+++ b/packages/next/src/next-devtools/dev-overlay/components/errors/error-message/error-message.tsx\n@@ -19,6 +19,10 @@ export function ErrorMessage({ errorMessage, errorType }: ErrorMessageProps) {\n     }\n   }, [errorMessage])\n \n+  if (!errorMessage) {\n+    return null\n+  }\n+\n   // The \"Blocking Route\" error message is specifically formatted to look nice\n   // in the overlay (rather than just passed through from the console), so we\n   // intentionally don't truncate it and rely on the scroll overflow instead.\ndiff --git a/packages/next/src/next-devtools/dev-overlay/container/errors.tsx b/packages/next/src/next-devtools/dev-overlay/container/errors.tsx\nindex 3768e40b061ee..7504d7ff28615 100644\n--- a/packages/next/src/next-devtools/dev-overlay/container/errors.tsx\n+++ b/packages/next/src/next-devtools/dev-overlay/container/errors.tsx\n@@ -55,6 +55,11 @@ function GenericErrorDescription({ error }: { error: Error }) {\n     message = message.slice(envPrefix.length)\n   }\n \n+  message = message.trim()\n+  if (!message) {\n+    return null\n+  }\n+\n   return (\n     <>\n       <HotlinkedText text={message} matcher={matchLinkType} />\ndiff --git a/packages/next/src/next-devtools/dev-overlay/container/runtime-error/error-cause.tsx b/packages/next/src/next-devtools/dev-overlay/container/runtime-error/error-cause.tsx\nindex 64c0ec6542e73..8169c24ca0e5d 100644\n--- a/packages/next/src/next-devtools/dev-overlay/container/runtime-error/error-cause.tsx\n+++ b/packages/next/src/next-devtools/dev-overlay/container/runtime-error/error-cause.tsx\n@@ -11,6 +11,7 @@ type ErrorCauseProps = {\n \n export function ErrorCause({ cause, dialogResizerRef }: ErrorCauseProps) {\n   const frames = React.use(cause.frames())\n+  const trimmedMessage = cause.error.message.trim()\n \n   const firstFrame = useMemo(() => {\n     const index = frames.findIndex(\n@@ -29,7 +30,9 @@ export function ErrorCause({ cause, dialogResizerRef }: ErrorCauseProps) {\n           Caused by: {cause.error.name || 'Error'}\n         </span>\n       </div>\n-      <p className=\"error-cause-message\">{cause.error.message}</p>\n+      {trimmedMessage ? (\n+        <p className=\"error-cause-message\">{trimmedMessage}</p>\n+      ) : null}\n \n       {firstFrame && (\n         <CodeFrame\ndiff --git a/test/e2e/app-dir/instant-validation-causes/instant-validation-causes.test.ts b/test/e2e/app-dir/instant-validation-causes/instant-validation-causes.test.ts\nindex 204bee76ef8c4..6cabdf194cd0e 100644\n--- a/test/e2e/app-dir/instant-validation-causes/instant-validation-causes.test.ts\n+++ b/test/e2e/app-dir/instant-validation-causes/instant-validation-causes.test.ts\n@@ -96,7 +96,6 @@ describe('instant validation causes', () => {\n        \"cause\": [\n          {\n            \"label\": \"Caused by: Instant Validation\",\n-           \"message\": \" \",\n            \"source\": \"app/named-export/page.tsx (3:26) @ unstable_instant\n      > 3 | const unstable_instant = { prefetch: 'static' }\n          |                          ^\",\n@@ -141,7 +140,6 @@ describe('instant validation causes', () => {\n        \"cause\": [\n          {\n            \"label\": \"Caused by: Instant Validation\",\n-           \"message\": \" \",\n            \"source\": \"app/aliased-export/page.tsx (3:17) @ unstable_instant\n      > 3 | const instant = { prefetch: 'static' }\n          |                 ^\",\n@@ -186,7 +184,6 @@ describe('instant validation causes', () => {\n        \"cause\": [\n          {\n            \"label\": \"Caused by: Instant Validation\",\n-           \"message\": \" \",\n            \"source\": \"app/reexport/page.tsx (3:10) @ unstable_instant\n      > 3 | export { unstable_instant } from './config'\n          |          ^\",\n@@ -234,7 +231,6 @@ describe('instant validation causes', () => {\n        \"cause\": [\n          {\n            \"label\": \"Caused by: Instant Validation\",\n-           \"message\": \" \",\n            \"source\": \"app/indirect-export/page.tsx (4:17) @ unstable_instant\n      > 4 | const instant = _instant\n          |                 ^\",\ndiff --git a/test/e2e/app-dir/instant-validation/instant-validation.test.ts b/test/e2e/app-dir/instant-validation/instant-validation.test.ts\nindex 877649192a3ec..aab515d4d4d6d 100644\n--- a/test/e2e/app-dir/instant-validation/instant-validation.test.ts\n+++ b/test/e2e/app-dir/instant-validation/instant-validation.test.ts\n@@ -189,7 +189,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-runtime/page.tsx (3:33) @ unstable_instant\n        > 3 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -234,7 +233,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-dynamic/page.tsx (3:33) @ unstable_instant\n        > 3 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -277,7 +275,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/runtime/missing-suspense-around-dynamic/page.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = {\n            |                                 ^\",\n@@ -322,7 +319,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-dynamic-layout/layout.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -367,7 +363,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/runtime/missing-suspense-around-dynamic-layout/layout.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = {\n            |                                 ^\",\n@@ -411,7 +406,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-params/[param]/page.tsx (1:33) @ unstable_instant\n        > 1 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -465,7 +459,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/missing-suspense-around-search-params/page.tsx (1:33) @ unstable_instant\n        > 1 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -532,7 +525,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/suspense-too-high/page.tsx (3:33) @ unstable_instant\n        > 3 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -577,7 +569,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/runtime/suspense-too-high/page.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = {\n            |                                 ^\",\n@@ -707,7 +698,6 @@ describe('instant validation', () => {\n          \"cause\": [\n            {\n              \"label\": \"Caused by: Instant Validation\",\n-             \"message\": \" \",\n              \"source\": \"app/suspense-in-root/static/invalid-only-loading-around-dynamic/page.tsx (4:33) @ unstable_instant\n        > 4 | export const unstable_instant = { prefetch: 'static' }\n            |                                 ^\",\n@@ -759,7 +749,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/blocking-layout/missing-suspense-around-dynamic/page.tsx (3:33) @ unstable_instant\n          > 3 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -818,7 +807,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/invalid-blocking-inside-static/layout.tsx (1:33) @ unstable_instant\n          > 1 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -863,7 +851,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/runtime/invalid-blocking-inside-runtime/layout.tsx (3:33) @ unstable_instant\n          > 3 | export const unstable_instant = {\n              |                                 ^\",\n@@ -909,7 +896,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/missing-suspense-in-parallel-route/page.tsx (3:33) @ unstable_instant\n          > 3 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -955,7 +941,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/missing-suspense-in-parallel-route/foo/page.tsx (1:33) @ unstable_instant\n          > 1 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -1001,7 +986,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/missing-suspense-in-parallel-route/bar/page.tsx (1:33) @ unstable_instant\n          > 1 | export const unstable_instant = { prefetch: 'static' }\n              |                                 ^\",\n@@ -1049,7 +1033,6 @@ describe('instant validation', () => {\n            \"cause\": [\n              {\n                \"label\": \"Caused by: Instant Validation\",\n-               \"message\": \" \",\n                \"source\": \"app/suspense-in-root/static/invalid-client-data-blocks-validation/page.tsx (1:33) @ unstable_instant\n          > 1 | export const unstable_instant = {\n              |                                 ^\",\ndiff --git a/test/lib/add-redbox-matchers.ts b/test/lib/add-redbox-matchers.ts\nindex eb72703f1827e..700037007e7e9 100644\n--- a/test/lib/add-redbox-matchers.ts\n+++ b/test/lib/add-redbox-matchers.ts\n@@ -75,7 +75,7 @@ interface ErrorSnapshotOptions {\n \n interface SanitizedCauseEntry {\n   label: string | null\n-  message: string | null\n+  message?: string\n   source: string | null\n   stack: string[]\n }\n@@ -83,7 +83,7 @@ interface SanitizedCauseEntry {\n export interface ErrorSnapshot {\n   environmentLabel: string | null\n   label: string | null\n-  description: string | null\n+  description?: string\n   componentStack?: string\n   cause?: SanitizedCauseEntry[]\n   source: string | null\n@@ -239,11 +239,14 @@ async function createErrorSnapshot(\n   const snapshot: ErrorSnapshot = {\n     environmentLabel,\n     label: label ?? '<FIXME-excluded-label>',\n-    description: sanitizedDescription,\n     source: focusedSource,\n     stack: sanitizeStack(stack, next),\n   }\n \n+  if (sanitizedDescription !== null) {\n+    snapshot.description = sanitizedDescription\n+  }\n+\n   // Hydration diffs are only relevant to some specific errors\n   // so we hide them from the snapshots unless they are present.\n   if (componentStack !== null) {\n@@ -252,12 +255,17 @@ async function createErrorSnapshot(\n \n   // Error.cause chain is only relevant when present.\n   if (cause !== null) {\n-    snapshot.cause = cause.map((entry) => ({\n-      label: entry.label,\n-      message: entry.message,\n-      source: focusSource(entry.source, next),\n-      stack: sanitizeStack(entry.stack, next) ?? [],\n-    }))\n+    snapshot.cause = cause.map((entry) => {\n+      const causeEntry: SanitizedCauseEntry = {\n+        label: entry.label,\n+        source: focusSource(entry.source, next),\n+        stack: sanitizeStack(entry.stack, next) ?? [],\n+      }\n+      if (entry.message !== null) {\n+        causeEntry.message = entry.message\n+      }\n+      return causeEntry\n+    })\n   }\n \n   return snapshot\n",
      "results": [
        {
          "modelId": "anthropic/claude-opus-4.5",
          "tier": "frontier",
          "status": "success",
          "message": "fix(next-devtools): hide empty error messages in dev overlay",
          "latencyMs": 3703,
          "costUsd": 0.023185,
          "inputTokens": 4552,
          "outputTokens": 17,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "anthropic": {
              "usage": {
                "input_tokens": 4552,
                "output_tokens": 17,
                "cache_creation_input_tokens": 0,
                "cache_read_input_tokens": 0,
                "cache_creation": {
                  "ephemeral_5m_input_tokens": 0,
                  "ephemeral_1h_input_tokens": 0
                },
                "service_tier": "standard",
                "inference_geo": "not_available"
              },
              "cacheCreationInputTokens": 0,
              "stopSequence": null,
              "iterations": null,
              "container": null,
              "contextManagement": null
            },
            "gateway": {
              "routing": {
                "originalModelId": "anthropic/claude-opus-4.5",
                "resolvedProvider": "anthropic",
                "resolvedProviderApiModelId": "claude-opus-4-5-20251101",
                "internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
                "fallbacksAvailable": [
                  "vertexAnthropic",
                  "bedrock"
                ],
                "internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
                "planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
                "canonicalSlug": "anthropic/claude-opus-4.5",
                "finalProvider": "anthropic",
                "attempts": [
                  {
                    "provider": "anthropic",
                    "internalModelId": "anthropic:claude-opus-4-5-20251101",
                    "providerApiModelId": "claude-opus-4-5-20251101",
                    "credentialType": "byok",
                    "success": true,
                    "startTime": 562226.089703,
                    "endTime": 565585.688004,
                    "statusCode": 200,
                    "providerResponseId": "msg_012VzWb7m2CSsKNK6r2mpAvT"
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "anthropic/claude-opus-4.5",
                    "canonicalSlug": "anthropic/claude-opus-4.5",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0",
              "marketCost": "0.023185",
              "generationId": "gen_01KJ5JXJWK50WV5TE90AGP0D0B",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "anthropic/claude-sonnet-4.6",
          "tier": "frontier",
          "status": "success",
          "message": "fix(dev-overlay): hide empty or whitespace-only error messages in overlay",
          "latencyMs": 1766,
          "costUsd": 0.013959,
          "inputTokens": 4553,
          "outputTokens": 20,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "anthropic": {
              "usage": {
                "input_tokens": 4553,
                "output_tokens": 20,
                "cache_creation_input_tokens": 0,
                "cache_read_input_tokens": 0,
                "cache_creation": {
                  "ephemeral_5m_input_tokens": 0,
                  "ephemeral_1h_input_tokens": 0
                },
                "service_tier": "standard",
                "inference_geo": "global"
              },
              "cacheCreationInputTokens": 0,
              "stopSequence": null,
              "iterations": null,
              "container": null,
              "contextManagement": null
            },
            "gateway": {
              "routing": {
                "originalModelId": "anthropic/claude-sonnet-4.6",
                "resolvedProvider": "anthropic",
                "resolvedProviderApiModelId": "claude-sonnet-4-6",
                "internalResolvedModelId": "anthropic:claude-sonnet-4-6",
                "fallbacksAvailable": [
                  "vertexAnthropic",
                  "bedrock"
                ],
                "internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
                "planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
                "canonicalSlug": "anthropic/claude-sonnet-4.6",
                "finalProvider": "anthropic",
                "attempts": [
                  {
                    "provider": "anthropic",
                    "internalModelId": "anthropic:claude-sonnet-4-6",
                    "providerApiModelId": "claude-sonnet-4-6",
                    "credentialType": "byok",
                    "success": true,
                    "startTime": 1104980.800204,
                    "endTime": 1106413.497357,
                    "statusCode": 200,
                    "providerResponseId": "msg_018WNXSiY83Mhg5XLmZaWLCM"
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "anthropic/claude-sonnet-4.6",
                    "canonicalSlug": "anthropic/claude-sonnet-4.6",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0",
              "marketCost": "0.013959",
              "generationId": "gen_01KJ5JXN34NGY7GR3WJP2B5PCA",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "cerebras/llama3.1-8b",
          "tier": "small",
          "status": "success",
          "message": "feat(core): trim error messages",
          "latencyMs": 675,
          "costUsd": 0.0003628,
          "inputTokens": 3621,
          "outputTokens": 7,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "cerebras": {
              "acceptedPredictionTokens": 0,
              "rejectedPredictionTokens": 0
            },
            "gateway": {
              "routing": {
                "originalModelId": "cerebras/llama3.1-8b",
                "resolvedProvider": "cerebras",
                "resolvedProviderApiModelId": "llama3.1-8b",
                "internalResolvedModelId": "cerebras:llama3.1-8b",
                "fallbacksAvailable": [],
                "internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
                "planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
                "canonicalSlug": "meta/llama-3.1-8b",
                "finalProvider": "cerebras",
                "attempts": [
                  {
                    "provider": "cerebras",
                    "internalModelId": "cerebras:llama3.1-8b",
                    "providerApiModelId": "llama3.1-8b",
                    "credentialType": "system",
                    "success": true,
                    "startTime": 745671.266993,
                    "endTime": 746137.89566,
                    "statusCode": 200
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "cerebras/llama3.1-8b",
                    "canonicalSlug": "cerebras/llama3.1-8b",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0.0003628",
              "marketCost": "0.0003628",
              "generationId": "gen_01KJ5JXJ0M7C6ZCA1GVEM0N7S8",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "google/gemini-3-pro-preview",
          "tier": "frontier",
          "status": "success",
          "message": "fix(",
          "latencyMs": 3741,
          "costUsd": 0.010166,
          "inputTokens": 4387,
          "outputTokens": 116,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "vertex": {
              "promptFeedback": null,
              "groundingMetadata": null,
              "urlContextMetadata": null,
              "safetyRatings": null,
              "usageMetadata": {
                "thoughtsTokenCount": 114,
                "promptTokenCount": 4387,
                "candidatesTokenCount": 2,
                "totalTokenCount": 4503,
                "trafficType": "ON_DEMAND"
              }
            },
            "gateway": {
              "routing": {
                "originalModelId": "google/gemini-3-pro-preview",
                "resolvedProvider": "vertex",
                "resolvedProviderApiModelId": "gemini-3-pro-preview",
                "internalResolvedModelId": "vertex:gemini-3-pro-preview",
                "fallbacksAvailable": [
                  "google"
                ],
                "internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
                "planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
                "canonicalSlug": "google/gemini-3-pro-preview",
                "finalProvider": "vertex",
                "attempts": [
                  {
                    "provider": "vertex",
                    "internalModelId": "vertex:gemini-3-pro-preview",
                    "providerApiModelId": "gemini-3-pro-preview",
                    "credentialType": "byok",
                    "success": true,
                    "startTime": 25736.13052,
                    "endTime": 29277.701302,
                    "statusCode": 200,
                    "providerResponseId": "fXacadGoHriFw-UP8eHU4AM"
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "google/gemini-3-pro-preview",
                    "canonicalSlug": "google/gemini-3-pro-preview",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0",
              "marketCost": "0.010166",
              "generationId": "gen_01KJ5JXPBT3P1QN4MGR5PZBZP9",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "mistral/codestral",
          "tier": "small",
          "status": "success",
          "message": "fix(dev-overlay): add null checks for error messages",
          "latencyMs": 944,
          "costUsd": 0.001173,
          "inputTokens": 3874,
          "outputTokens": 12,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "gateway": {
              "routing": {
                "originalModelId": "mistral/codestral",
                "resolvedProvider": "mistral",
                "resolvedProviderApiModelId": "codestral-latest",
                "internalResolvedModelId": "mistral:codestral-latest",
                "fallbacksAvailable": [],
                "internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
                "planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
                "canonicalSlug": "mistral/codestral",
                "finalProvider": "mistral",
                "attempts": [
                  {
                    "provider": "mistral",
                    "internalModelId": "mistral:codestral-latest",
                    "providerApiModelId": "codestral-latest",
                    "credentialType": "system",
                    "success": true,
                    "startTime": 93288.120998,
                    "endTime": 93670.069565,
                    "statusCode": 200
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "mistral/codestral",
                    "canonicalSlug": "mistral/codestral",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0.001173",
              "marketCost": "0.001173",
              "generationId": "gen_01KJ69JFMTNPERZPCVD7SM08J8",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "mistral/ministral-3b",
          "tier": "small",
          "status": "success",
          "message": "feat(devtools): add null checks for error messages in error display",
          "latencyMs": 763,
          "costUsd": 0.00015552,
          "inputTokens": 3874,
          "outputTokens": 14,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "gateway": {
              "routing": {
                "originalModelId": "mistral/ministral-3b",
                "resolvedProvider": "mistral",
                "resolvedProviderApiModelId": "ministral-3b-latest",
                "internalResolvedModelId": "mistral:ministral-3b-latest",
                "fallbacksAvailable": [],
                "internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
                "planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
                "canonicalSlug": "mistral/ministral-3b",
                "finalProvider": "mistral",
                "attempts": [
                  {
                    "provider": "mistral",
                    "internalModelId": "mistral:ministral-3b-latest",
                    "providerApiModelId": "ministral-3b-latest",
                    "credentialType": "system",
                    "success": true,
                    "startTime": 1309462.981122,
                    "endTime": 1310025.728895,
                    "statusCode": 200
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "mistral/ministral-3b",
                    "canonicalSlug": "mistral/ministral-3b",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0.00015552",
              "marketCost": "0.00015552",
              "generationId": "gen_01KJ5JXJ011NE51QYXN8Q0796X",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "openai/gpt-5.2",
          "tier": "frontier",
          "status": "success",
          "message": "fix(dev-overlay): trim and omit empty error messages in redbox snapshots",
          "latencyMs": 2356,
          "costUsd": 0.00659575,
          "inputTokens": 3625,
          "outputTokens": 18,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "openai": {
              "responseId": "resp_01c39aceffc185f800699c767a58c4819faa96eebe5df908ea",
              "serviceTier": "default"
            },
            "gateway": {
              "routing": {
                "originalModelId": "openai/gpt-5.2",
                "resolvedProvider": "openai",
                "resolvedProviderApiModelId": "gpt-5.2",
                "internalResolvedModelId": "openai:gpt-5.2",
                "fallbacksAvailable": [
                  "azure"
                ],
                "internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
                "planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
                "canonicalSlug": "openai/gpt-5.2",
                "finalProvider": "openai",
                "attempts": [
                  {
                    "provider": "openai",
                    "internalModelId": "openai:gpt-5.2",
                    "providerApiModelId": "gpt-5.2",
                    "credentialType": "byok",
                    "success": true,
                    "startTime": 1102635.021867,
                    "endTime": 1104654.852803,
                    "statusCode": 200,
                    "providerResponseId": "resp_01c39aceffc185f800699c767a58c4819faa96eebe5df908ea"
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "openai/gpt-5.2",
                    "canonicalSlug": "openai/gpt-5.2",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0",
              "marketCost": "0.00659575",
              "generationId": "gen_01KJ5JXJSQMFHRA5QHFNG8K2X6",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "xai/grok-code-fast-1",
          "tier": "small",
          "status": "success",
          "message": "fix(dev-overlay): trim and hide empty error messages in dev overlay",
          "latencyMs": 15523,
          "costUsd": 0.00114608,
          "inputTokens": 3721,
          "outputTokens": 314,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "gateway": {
              "routing": {
                "originalModelId": "xai/grok-code-fast-1",
                "resolvedProvider": "xai",
                "resolvedProviderApiModelId": "grok-code-fast-1",
                "internalResolvedModelId": "xai:grok-code-fast-1",
                "fallbacksAvailable": [],
                "internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
                "planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
                "canonicalSlug": "xai/grok-code-fast-1",
                "finalProvider": "xai",
                "attempts": [
                  {
                    "provider": "xai",
                    "internalModelId": "xai:grok-code-fast-1",
                    "providerApiModelId": "grok-code-fast-1",
                    "credentialType": "system",
                    "success": true,
                    "startTime": 745857.614619,
                    "endTime": 760982.753698,
                    "statusCode": 200
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "xai/grok-code-fast-1",
                    "canonicalSlug": "xai/grok-code-fast-1",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0.00114608",
              "marketCost": "0.00114608",
              "generationId": "gen_01KJ5JXJ4VE5T3X0HE2WECRC2Q",
              "billableWebSearchCalls": 0
            }
          }
        }
      ]
    },
    {
      "id": "zed-9304e02b-agent-allow-the-agent-to-reprompt-a",
      "title": "agent: Allow the agent to reprompt an existing subagent (#49737)",
      "sourceRepo": "zed-industries/zed",
      "sourceCommitUrl": "https://github.com/zed-industries/zed/commit/9304e02b9a2e72169d9082f56fce2c632a02a8eb",
      "diff": "diff --git a/crates/agent/src/agent.rs b/crates/agent/src/agent.rs\nindex 8cea712c19cebb..4e8691c0b5017e 100644\n--- a/crates/agent/src/agent.rs\n+++ b/crates/agent/src/agent.rs\n@@ -1611,11 +1611,60 @@ impl NativeThreadEnvironment {\n             agent.register_session(subagent_thread.clone(), cx)\n         })?;\n \n+        Self::prompt_subagent(\n+            session_id,\n+            subagent_thread,\n+            acp_thread,\n+            parent_thread_entity,\n+            initial_prompt,\n+            timeout,\n+            cx,\n+        )\n+    }\n+\n+    pub(crate) fn resume_subagent_thread(\n+        agent: WeakEntity<NativeAgent>,\n+        parent_thread_entity: Entity<Thread>,\n+        session_id: acp::SessionId,\n+        follow_up_prompt: String,\n+        timeout: Option<Duration>,\n+        cx: &mut App,\n+    ) -> Result<Rc<dyn SubagentHandle>> {\n+        let (subagent_thread, acp_thread) = agent.update(cx, |agent, _cx| {\n+            let session = agent\n+                .sessions\n+                .get(&session_id)\n+                .ok_or_else(|| anyhow!(\"No subagent session found with id {session_id}\"))?;\n+            anyhow::Ok((session.thread.clone(), session.acp_thread.clone()))\n+        })??;\n+\n+        Self::prompt_subagent(\n+            session_id,\n+            subagent_thread,\n+            acp_thread,\n+            parent_thread_entity,\n+            follow_up_prompt,\n+            timeout,\n+            cx,\n+        )\n+    }\n+\n+    fn prompt_subagent(\n+        session_id: acp::SessionId,\n+        subagent_thread: Entity<Thread>,\n+        acp_thread: Entity<acp_thread::AcpThread>,\n+        parent_thread_entity: Entity<Thread>,\n+        prompt: String,\n+        timeout: Option<Duration>,\n+        cx: &mut App,\n+    ) -> Result<Rc<dyn SubagentHandle>> {\n         parent_thread_entity.update(cx, |parent_thread, _cx| {\n             parent_thread.register_running_subagent(subagent_thread.downgrade())\n         });\n \n-        let task = acp_thread.update(cx, |agent, cx| agent.send(vec![initial_prompt.into()], cx));\n+        let task = acp_thread.update(cx, |acp_thread, cx| {\n+            acp_thread.send(vec![prompt.into()], cx)\n+        });\n \n         let timeout_timer = timeout.map(|d| cx.background_executor().timer(d));\n         let wait_for_prompt_to_complete = cx\n@@ -1708,6 +1757,24 @@ impl ThreadEnvironment for NativeThreadEnvironment {\n             cx,\n         )\n     }\n+\n+    fn resume_subagent(\n+        &self,\n+        parent_thread_entity: Entity<Thread>,\n+        session_id: acp::SessionId,\n+        follow_up_prompt: String,\n+        timeout: Option<Duration>,\n+        cx: &mut App,\n+    ) -> Result<Rc<dyn SubagentHandle>> {\n+        Self::resume_subagent_thread(\n+            self.agent.clone(),\n+            parent_thread_entity,\n+            session_id,\n+            follow_up_prompt,\n+            timeout,\n+            cx,\n+        )\n+    }\n }\n \n #[derive(Debug, Clone, Copy)]\n@@ -1737,21 +1804,20 @@ impl SubagentHandle for NativeSubagentHandle {\n         let parent_thread = self.parent_thread.clone();\n \n         cx.spawn(async move |cx| {\n-            match wait_for_prompt.await {\n-                SubagentInitialPromptResult::Completed => {}\n+            let result = match wait_for_prompt.await {\n+                SubagentInitialPromptResult::Completed => thread.read_with(cx, |thread, _cx| {\n+                    thread\n+                        .last_message()\n+                        .map(|m| m.to_markdown())\n+                        .context(\"No response from subagent\")\n+                }),\n                 SubagentInitialPromptResult::Timeout => {\n-                    return Err(anyhow!(\"The time to complete the task was exceeded.\"));\n+                    thread.update(cx, |thread, cx| thread.cancel(cx)).await;\n+                    Err(anyhow!(\"The time to complete the task was exceeded.\"))\n                 }\n-                SubagentInitialPromptResult::Cancelled => return Err(anyhow!(\"User cancelled\")),\n+                SubagentInitialPromptResult::Cancelled => Err(anyhow!(\"User cancelled\")),\n             };\n \n-            let result = thread.read_with(cx, |thread, _cx| {\n-                thread\n-                    .last_message()\n-                    .map(|m| m.to_markdown())\n-                    .context(\"No response from subagent\")\n-            });\n-\n             parent_thread\n                 .update(cx, |parent_thread, cx| {\n                     parent_thread.unregister_running_subagent(&subagent_session_id, cx)\ndiff --git a/crates/agent/src/tests/mod.rs b/crates/agent/src/tests/mod.rs\nindex d895557fc1dec3..2673e33d0e7c8a 100644\n--- a/crates/agent/src/tests/mod.rs\n+++ b/crates/agent/src/tests/mod.rs\n@@ -4233,6 +4233,7 @@ async fn test_subagent_tool_call_end_to_end(cx: &mut TestAppContext) {\n     let subagent_tool_input = SubagentToolInput {\n         label: \"label\".to_string(),\n         task: \"subagent task prompt\".to_string(),\n+        session_id: None,\n         timeout_secs: None,\n     };\n     let subagent_tool_use = LanguageModelToolUse {\n@@ -4383,6 +4384,7 @@ async fn test_subagent_tool_call_cancellation_during_task_prompt(cx: &mut TestAp\n     let subagent_tool_input = SubagentToolInput {\n         label: \"label\".to_string(),\n         task: \"subagent task prompt\".to_string(),\n+        session_id: None,\n         timeout_secs: None,\n     };\n     let subagent_tool_use = LanguageModelToolUse {\n@@ -4460,6 +4462,195 @@ async fn test_subagent_tool_call_cancellation_during_task_prompt(cx: &mut TestAp\n     });\n }\n \n+#[gpui::test]\n+async fn test_subagent_tool_resume_session(cx: &mut TestAppContext) {\n+    init_test(cx);\n+    cx.update(|cx| {\n+        LanguageModelRegistry::test(cx);\n+    });\n+    cx.update(|cx| {\n+        cx.update_flags(true, vec![\"subagents\".to_string()]);\n+    });\n+\n+    let fs = FakeFs::new(cx.executor());\n+    fs.insert_tree(\n+        \"/\",\n+        json!({\n+            \"a\": {\n+                \"b.md\": \"Lorem\"\n+            }\n+        }),\n+    )\n+    .await;\n+    let project = Project::test(fs.clone(), [path!(\"/a\").as_ref()], cx).await;\n+    let thread_store = cx.new(|cx| ThreadStore::new(cx));\n+    let agent = NativeAgent::new(\n+        project.clone(),\n+        thread_store.clone(),\n+        Templates::new(),\n+        None,\n+        fs.clone(),\n+        &mut cx.to_async(),\n+    )\n+    .await\n+    .unwrap();\n+    let connection = Rc::new(NativeAgentConnection(agent.clone()));\n+\n+    let acp_thread = cx\n+        .update(|cx| {\n+            connection\n+                .clone()\n+                .new_session(project.clone(), Path::new(\"\"), cx)\n+        })\n+        .await\n+        .unwrap();\n+    let session_id = acp_thread.read_with(cx, |thread, _| thread.session_id().clone());\n+    let thread = agent.read_with(cx, |agent, _| {\n+        agent.sessions.get(&session_id).unwrap().thread.clone()\n+    });\n+    let model = Arc::new(FakeLanguageModel::default());\n+\n+    thread.update(cx, |thread, cx| {\n+        thread.set_model(model.clone(), cx);\n+    });\n+    cx.run_until_parked();\n+\n+    // === First turn: create subagent ===\n+    let send = acp_thread.update(cx, |thread, cx| thread.send_raw(\"First prompt\", cx));\n+    cx.run_until_parked();\n+    model.send_last_completion_stream_text_chunk(\"spawning subagent\");\n+    let subagent_tool_input = SubagentToolInput {\n+        label: \"initial task\".to_string(),\n+        task: \"do the first task\".to_string(),\n+        session_id: None,\n+        timeout_secs: None,\n+    };\n+    let subagent_tool_use = LanguageModelToolUse {\n+        id: \"subagent_1\".into(),\n+        name: SubagentTool::NAME.into(),\n+        raw_input: serde_json::to_string(&subagent_tool_input).unwrap(),\n+        input: serde_json::to_value(&subagent_tool_input).unwrap(),\n+        is_input_complete: true,\n+        thought_signature: None,\n+    };\n+    model.send_last_completion_stream_event(LanguageModelCompletionEvent::ToolUse(\n+        subagent_tool_use,\n+    ));\n+    model.end_last_completion_stream();\n+\n+    cx.run_until_parked();\n+\n+    let subagent_session_id = thread.read_with(cx, |thread, cx| {\n+        thread\n+            .running_subagent_ids(cx)\n+            .get(0)\n+            .expect(\"subagent thread should be running\")\n+            .clone()\n+    });\n+\n+    let subagent_acp_thread = agent.read_with(cx, |agent, _cx| {\n+        agent\n+            .sessions\n+            .get(&subagent_session_id)\n+            .expect(\"subagent session should exist\")\n+            .acp_thread\n+            .clone()\n+    });\n+\n+    // Subagent responds\n+    model.send_last_completion_stream_text_chunk(\"first task response\");\n+    model.end_last_completion_stream();\n+\n+    cx.run_until_parked();\n+\n+    // Parent model responds to complete first turn\n+    model.send_last_completion_stream_text_chunk(\"First response\");\n+    model.end_last_completion_stream();\n+\n+    send.await.unwrap();\n+\n+    // Verify subagent is no longer running\n+    thread.read_with(cx, |thread, cx| {\n+        assert!(\n+            thread.running_subagent_ids(cx).is_empty(),\n+            \"subagent should not be running after completion\"\n+        );\n+    });\n+\n+    // === Second turn: resume subagent with session_id ===\n+    let send2 = acp_thread.update(cx, |thread, cx| thread.send_raw(\"Follow up\", cx));\n+    cx.run_until_parked();\n+    model.send_last_completion_stream_text_chunk(\"resuming subagent\");\n+    let resume_tool_input = SubagentToolInput {\n+        label: \"follow-up task\".to_string(),\n+        task: \"do the follow-up task\".to_string(),\n+        session_id: Some(subagent_session_id.clone()),\n+        timeout_secs: None,\n+    };\n+    let resume_tool_use = LanguageModelToolUse {\n+        id: \"subagent_2\".into(),\n+        name: SubagentTool::NAME.into(),\n+        raw_input: serde_json::to_string(&resume_tool_input).unwrap(),\n+        input: serde_json::to_value(&resume_tool_input).unwrap(),\n+        is_input_complete: true,\n+        thought_signature: None,\n+    };\n+    model.send_last_completion_stream_event(LanguageModelCompletionEvent::ToolUse(resume_tool_use));\n+    model.end_last_completion_stream();\n+\n+    cx.run_until_parked();\n+\n+    // Subagent should be running again with the same session\n+    thread.read_with(cx, |thread, cx| {\n+        let running = thread.running_subagent_ids(cx);\n+        assert_eq!(running.len(), 1, \"subagent should be running\");\n+        assert_eq!(running[0], subagent_session_id, \"should be same session\");\n+    });\n+\n+    // Subagent responds to follow-up\n+    model.send_last_completion_stream_text_chunk(\"follow-up task response\");\n+    model.end_last_completion_stream();\n+\n+    cx.run_until_parked();\n+\n+    // Parent model responds to complete second turn\n+    model.send_last_completion_stream_text_chunk(\"Second response\");\n+    model.end_last_completion_stream();\n+\n+    send2.await.unwrap();\n+\n+    // Verify subagent is no longer running\n+    thread.read_with(cx, |thread, cx| {\n+        assert!(\n+            thread.running_subagent_ids(cx).is_empty(),\n+            \"subagent should not be running after resume completion\"\n+        );\n+    });\n+\n+    // Verify the subagent's acp thread has both conversation turns\n+    assert_eq!(\n+        subagent_acp_thread.read_with(cx, |thread, cx| thread.to_markdown(cx)),\n+        indoc! {\"\n+            ## User\n+\n+            do the first task\n+\n+            ## Assistant\n+\n+            first task response\n+\n+            ## User\n+\n+            do the follow-up task\n+\n+            ## Assistant\n+\n+            follow-up task response\n+\n+        \"}\n+    );\n+}\n+\n #[gpui::test]\n async fn test_subagent_tool_is_present_when_feature_flag_enabled(cx: &mut TestAppContext) {\n     init_test(cx);\ndiff --git a/crates/agent/src/thread.rs b/crates/agent/src/thread.rs\nindex 93024a97073e6f..cc8a46987d0d01 100644\n--- a/crates/agent/src/thread.rs\n+++ b/crates/agent/src/thread.rs\n@@ -621,6 +621,19 @@ pub trait ThreadEnvironment {\n         timeout: Option<Duration>,\n         cx: &mut App,\n     ) -> Result<Rc<dyn SubagentHandle>>;\n+\n+    fn resume_subagent(\n+        &self,\n+        _parent_thread: Entity<Thread>,\n+        _session_id: acp::SessionId,\n+        _follow_up_prompt: String,\n+        _timeout: Option<Duration>,\n+        _cx: &mut App,\n+    ) -> Result<Rc<dyn SubagentHandle>> {\n+        Err(anyhow::anyhow!(\n+            \"Resuming subagent sessions is not supported\"\n+        ))\n+    }\n }\n \n #[derive(Debug)]\ndiff --git a/crates/agent/src/tools/subagent_tool.rs b/crates/agent/src/tools/subagent_tool.rs\nindex 1c9487dcbe611f..8212192d7bfc51 100644\n--- a/crates/agent/src/tools/subagent_tool.rs\n+++ b/crates/agent/src/tools/subagent_tool.rs\n@@ -23,6 +23,8 @@ use crate::{AgentTool, Thread, ThreadEnvironment, ToolCallEventStream};\n ///\n /// You will receive only the agent's final message as output.\n ///\n+/// If a response (success or error) includes a session_id, you can send a follow-up message to that session by passing the session_id back. This is useful for multi-turn conversations with a subagent, asking clarifying questions about its output, or retrying after timeouts or transient failures.\n+///\n /// Note:\n /// - Agents cannot use tools you don't have access to.\n /// - If spawning multiple agents that might write to the filesystem, provide guidance on how to avoid conflicts (e.g. assign each to different directories).\n@@ -32,6 +34,9 @@ pub struct SubagentToolInput {\n     pub label: String,\n     /// Describe the task for the agent to perform. Be specific about what you want accomplished. Include all necessary context (file paths, requirements, constraints) since the agent cannot see your conversation.\n     pub task: String,\n+    /// Optional session ID of an existing subagent to continue a conversation with. When provided, the task is sent as a follow-up message to that session instead of creating a new one. Use this to ask clarifying questions, request changes based on previous output, or retry after errors.\n+    #[serde(default)]\n+    pub session_id: Option<acp::SessionId>,\n     /// Optional maximum runtime in seconds. The purpose of this timeout is to prevent the agent from getting stuck in infinite loops, NOT to estimate task duration. Be generous if setting. If not set, the agent runs until it completes or is cancelled.\n     #[serde(default)]\n     pub timeout_secs: Option<u64>,\n@@ -45,18 +50,18 @@ pub enum SubagentToolOutput {\n         output: String,\n     },\n     Error {\n+        #[serde(skip_serializing_if = \"Option::is_none\")]\n+        #[serde(default)]\n+        session_id: Option<acp::SessionId>,\n         error: String,\n     },\n }\n \n impl From<SubagentToolOutput> for LanguageModelToolResultContent {\n     fn from(output: SubagentToolOutput) -> Self {\n-        match output {\n-            output @ SubagentToolOutput::Success { .. } => serde_json::to_string(&output)\n-                .unwrap_or_else(|e| format!(\"Failed to serialize subagent output: {e}\"))\n-                .into(),\n-            SubagentToolOutput::Error { error } => error.into(),\n-        }\n+        serde_json::to_string(&output)\n+            .unwrap_or_else(|e| format!(\"Failed to serialize subagent output: {e}\"))\n+            .into()\n     }\n }\n \n@@ -103,25 +108,37 @@ impl AgentTool for SubagentTool {\n     ) -> Task<Result<Self::Output, Self::Output>> {\n         let Some(parent_thread_entity) = self.parent_thread.upgrade() else {\n             return Task::ready(Err(SubagentToolOutput::Error {\n+                session_id: None,\n                 error: \"Parent thread no longer exists\".to_string(),\n             }));\n         };\n \n-        let subagent = match self.environment.create_subagent(\n-            parent_thread_entity,\n-            input.label,\n-            input.task,\n-            input.timeout_secs.map(|secs| Duration::from_secs(secs)),\n-            cx,\n-        ) {\n+        let subagent = if let Some(session_id) = input.session_id {\n+            self.environment.resume_subagent(\n+                parent_thread_entity,\n+                session_id,\n+                input.task,\n+                input.timeout_secs.map(Duration::from_secs),\n+                cx,\n+            )\n+        } else {\n+            self.environment.create_subagent(\n+                parent_thread_entity,\n+                input.label,\n+                input.task,\n+                input.timeout_secs.map(Duration::from_secs),\n+                cx,\n+            )\n+        };\n+        let subagent = match subagent {\n             Ok(subagent) => subagent,\n             Err(err) => {\n                 return Task::ready(Err(SubagentToolOutput::Error {\n+                    session_id: None,\n                     error: err.to_string(),\n                 }));\n             }\n         };\n-\n         let subagent_session_id = subagent.id();\n \n         event_stream.subagent_spawned(subagent_session_id.clone());\n@@ -137,6 +154,7 @@ impl AgentTool for SubagentTool {\n                     .wait_for_output(cx)\n                     .await\n                     .map_err(|e| SubagentToolOutput::Error {\n+                        session_id: Some(subagent_session_id.clone()),\n                         error: e.to_string(),\n                     })?;\n             Ok(SubagentToolOutput::Success {\n@@ -153,17 +171,20 @@ impl AgentTool for SubagentTool {\n         event_stream: ToolCallEventStream,\n         _cx: &mut App,\n     ) -> Result<()> {\n-        match output {\n-            SubagentToolOutput::Success { session_id, .. } => {\n-                event_stream.subagent_spawned(session_id.clone());\n-                let meta = acp::Meta::from_iter([(\n-                    SUBAGENT_SESSION_ID_META_KEY.into(),\n-                    session_id.to_string().into(),\n-                )]);\n-                event_stream.update_fields_with_meta(acp::ToolCallUpdateFields::new(), Some(meta));\n-            }\n-            SubagentToolOutput::Error { .. } => {}\n+        let session_id = match &output {\n+            SubagentToolOutput::Success { session_id, .. } => Some(session_id),\n+            SubagentToolOutput::Error { session_id, .. } => session_id.as_ref(),\n+        };\n+\n+        if let Some(session_id) = session_id {\n+            event_stream.subagent_spawned(session_id.clone());\n+            let meta = acp::Meta::from_iter([(\n+                SUBAGENT_SESSION_ID_META_KEY.into(),\n+                session_id.to_string().into(),\n+            )]);\n+            event_stream.update_fields_with_meta(acp::ToolCallUpdateFields::new(), Some(meta));\n         }\n+\n         Ok(())\n     }\n }\n",
      "results": [
        {
          "modelId": "anthropic/claude-opus-4.5",
          "tier": "frontier",
          "status": "success",
          "message": "feat(agent): add subagent session resumption support",
          "latencyMs": 2176,
          "costUsd": 0.03168,
          "inputTokens": 6261,
          "outputTokens": 15,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "anthropic": {
              "usage": {
                "input_tokens": 6261,
                "output_tokens": 15,
                "cache_creation_input_tokens": 0,
                "cache_read_input_tokens": 0,
                "cache_creation": {
                  "ephemeral_5m_input_tokens": 0,
                  "ephemeral_1h_input_tokens": 0
                },
                "service_tier": "standard",
                "inference_geo": "not_available"
              },
              "cacheCreationInputTokens": 0,
              "stopSequence": null,
              "iterations": null,
              "container": null,
              "contextManagement": null
            },
            "gateway": {
              "routing": {
                "originalModelId": "anthropic/claude-opus-4.5",
                "resolvedProvider": "anthropic",
                "resolvedProviderApiModelId": "claude-opus-4-5-20251101",
                "internalResolvedModelId": "anthropic:claude-opus-4-5-20251101",
                "fallbacksAvailable": [
                  "vertexAnthropic",
                  "bedrock"
                ],
                "internalReasoning": "Selected anthropic as preferred provider for claude-opus-4.5. 2 fallback(s) available: vertexAnthropic, bedrock",
                "planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
                "canonicalSlug": "anthropic/claude-opus-4.5",
                "finalProvider": "anthropic",
                "attempts": [
                  {
                    "provider": "anthropic",
                    "internalModelId": "anthropic:claude-opus-4-5-20251101",
                    "providerApiModelId": "claude-opus-4-5-20251101",
                    "credentialType": "byok",
                    "success": true,
                    "startTime": 117810.090878,
                    "endTime": 119614.202878,
                    "statusCode": 200,
                    "providerResponseId": "msg_01YWhjRA3yHrDBR9e2KGKHXx"
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "anthropic/claude-opus-4.5",
                    "canonicalSlug": "anthropic/claude-opus-4.5",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0",
              "marketCost": "0.03168",
              "generationId": "gen_01KJ5JY231XP3XY5RBVBT5R5CB",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "anthropic/claude-sonnet-4.6",
          "tier": "frontier",
          "status": "success",
          "message": "feat(agent): add subagent session resumption via session_id in SubagentTool",
          "latencyMs": 1958,
          "costUsd": 0.019146,
          "inputTokens": 6262,
          "outputTokens": 24,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "anthropic": {
              "usage": {
                "input_tokens": 6262,
                "output_tokens": 24,
                "cache_creation_input_tokens": 0,
                "cache_read_input_tokens": 0,
                "cache_creation": {
                  "ephemeral_5m_input_tokens": 0,
                  "ephemeral_1h_input_tokens": 0
                },
                "service_tier": "standard",
                "inference_geo": "global"
              },
              "cacheCreationInputTokens": 0,
              "stopSequence": null,
              "iterations": null,
              "container": null,
              "contextManagement": null
            },
            "gateway": {
              "routing": {
                "originalModelId": "anthropic/claude-sonnet-4.6",
                "resolvedProvider": "anthropic",
                "resolvedProviderApiModelId": "claude-sonnet-4-6",
                "internalResolvedModelId": "anthropic:claude-sonnet-4-6",
                "fallbacksAvailable": [
                  "vertexAnthropic",
                  "bedrock"
                ],
                "internalReasoning": "Selected anthropic as preferred provider for claude-sonnet-4.6. 2 fallback(s) available: vertexAnthropic, bedrock",
                "planningReasoning": "BYOK credentials available for: anthropic, vertexAnthropic. System credentials planned for: anthropic, vertexAnthropic, bedrock. Total execution order: anthropic(BYOK) → vertexAnthropic(BYOK) → anthropic(system) → vertexAnthropic(system) → bedrock(system)",
                "canonicalSlug": "anthropic/claude-sonnet-4.6",
                "finalProvider": "anthropic",
                "attempts": [
                  {
                    "provider": "anthropic",
                    "internalModelId": "anthropic:claude-sonnet-4-6",
                    "providerApiModelId": "claude-sonnet-4-6",
                    "credentialType": "byok",
                    "success": true,
                    "startTime": 1040096.891303,
                    "endTime": 1041717.824838,
                    "statusCode": 200,
                    "providerResponseId": "msg_01C18iWW3JHP9hs278sXsEaF"
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "anthropic/claude-sonnet-4.6",
                    "canonicalSlug": "anthropic/claude-sonnet-4.6",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0",
              "marketCost": "0.019146",
              "generationId": "gen_01KJ5JY40HM1H07S921QQ7Y1X4",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "cerebras/llama3.1-8b",
          "tier": "small",
          "status": "success",
          "message": "feat(cli): add support for resuming subagent sessions",
          "latencyMs": 776,
          "costUsd": 0.0004562,
          "inputTokens": 4678,
          "outputTokens": 12,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "cerebras": {
              "acceptedPredictionTokens": 0,
              "rejectedPredictionTokens": 0
            },
            "gateway": {
              "routing": {
                "originalModelId": "cerebras/llama3.1-8b",
                "resolvedProvider": "cerebras",
                "resolvedProviderApiModelId": "llama3.1-8b",
                "internalResolvedModelId": "cerebras:llama3.1-8b",
                "fallbacksAvailable": [],
                "internalReasoning": "Used provider hint 'cerebras' for llama3.1-8b. 0 fallback(s) available: ",
                "planningReasoning": "System credentials planned for: cerebras. Total execution order: cerebras(system)",
                "canonicalSlug": "meta/llama-3.1-8b",
                "finalProvider": "cerebras",
                "attempts": [
                  {
                    "provider": "cerebras",
                    "internalModelId": "cerebras:llama3.1-8b",
                    "providerApiModelId": "llama3.1-8b",
                    "credentialType": "system",
                    "success": true,
                    "startTime": 1325126.644158,
                    "endTime": 1325561.410205,
                    "statusCode": 200
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "cerebras/llama3.1-8b",
                    "canonicalSlug": "cerebras/llama3.1-8b",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0.0004562",
              "marketCost": "0.0004562",
              "generationId": "gen_01KJ5JY19W2X3NFN21ACTM0V7S",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "google/gemini-3-pro-preview",
          "tier": "frontier",
          "status": "success",
          "message": "feat(agent): allow",
          "latencyMs": 3370,
          "costUsd": 0.013182,
          "inputTokens": 5895,
          "outputTokens": 116,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "vertex": {
              "promptFeedback": null,
              "groundingMetadata": null,
              "urlContextMetadata": null,
              "safetyRatings": null,
              "usageMetadata": {
                "thoughtsTokenCount": 111,
                "promptTokenCount": 5895,
                "candidatesTokenCount": 5,
                "totalTokenCount": 6011,
                "trafficType": "ON_DEMAND"
              }
            },
            "gateway": {
              "routing": {
                "originalModelId": "google/gemini-3-pro-preview",
                "resolvedProvider": "vertex",
                "resolvedProviderApiModelId": "gemini-3-pro-preview",
                "internalResolvedModelId": "vertex:gemini-3-pro-preview",
                "fallbacksAvailable": [
                  "google"
                ],
                "internalReasoning": "Selected vertex as preferred provider for gemini-3-pro-preview. 1 fallback(s) available: google",
                "planningReasoning": "BYOK credentials available for: vertex. System credentials planned for: vertex, google. Total execution order: vertex(BYOK) → vertex(system) → google(system)",
                "canonicalSlug": "google/gemini-3-pro-preview",
                "finalProvider": "vertex",
                "attempts": [
                  {
                    "provider": "vertex",
                    "internalModelId": "vertex:gemini-3-pro-preview",
                    "providerApiModelId": "gemini-3-pro-preview",
                    "credentialType": "byok",
                    "success": true,
                    "startTime": 1054500.494659,
                    "endTime": 1057496.188859,
                    "statusCode": 200,
                    "providerResponseId": "i3acaeDxJazCotkPt9XyuQM"
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "google/gemini-3-pro-preview",
                    "canonicalSlug": "google/gemini-3-pro-preview",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0",
              "marketCost": "0.013182",
              "generationId": "gen_01KJ5JY473TH8W1672V47ZSYYG",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "mistral/codestral",
          "tier": "small",
          "status": "success",
          "message": "feat(agent): add support for resuming subagent sessions",
          "latencyMs": 843,
          "costUsd": 0.0015096,
          "inputTokens": 4993,
          "outputTokens": 13,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "gateway": {
              "routing": {
                "originalModelId": "mistral/codestral",
                "resolvedProvider": "mistral",
                "resolvedProviderApiModelId": "codestral-latest",
                "internalResolvedModelId": "mistral:codestral-latest",
                "fallbacksAvailable": [],
                "internalReasoning": "Selected mistral as preferred provider for codestral. 0 fallback(s) available: ",
                "planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
                "canonicalSlug": "mistral/codestral",
                "finalProvider": "mistral",
                "attempts": [
                  {
                    "provider": "mistral",
                    "internalModelId": "mistral:codestral-latest",
                    "providerApiModelId": "codestral-latest",
                    "credentialType": "system",
                    "success": true,
                    "startTime": 1317037.36278,
                    "endTime": 1317544.538082,
                    "statusCode": 200
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "mistral/codestral",
                    "canonicalSlug": "mistral/codestral",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0.0015096",
              "marketCost": "0.0015096",
              "generationId": "gen_01KJ69JGBRAWGJJQ63GSNS5KTV",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "mistral/ministral-3b",
          "tier": "small",
          "status": "success",
          "message": "feat(agent): add subagent session resume functionality",
          "latencyMs": 671,
          "costUsd": 0.00020016,
          "inputTokens": 4993,
          "outputTokens": 11,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "gateway": {
              "routing": {
                "originalModelId": "mistral/ministral-3b",
                "resolvedProvider": "mistral",
                "resolvedProviderApiModelId": "ministral-3b-latest",
                "internalResolvedModelId": "mistral:ministral-3b-latest",
                "fallbacksAvailable": [],
                "internalReasoning": "Selected mistral as preferred provider for ministral-3b. 0 fallback(s) available: ",
                "planningReasoning": "System credentials planned for: mistral. Total execution order: mistral(system)",
                "canonicalSlug": "mistral/ministral-3b",
                "finalProvider": "mistral",
                "attempts": [
                  {
                    "provider": "mistral",
                    "internalModelId": "mistral:ministral-3b-latest",
                    "providerApiModelId": "ministral-3b-latest",
                    "credentialType": "system",
                    "success": true,
                    "startTime": 2823998.940189,
                    "endTime": 2824328.41076,
                    "statusCode": 200
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "mistral/ministral-3b",
                    "canonicalSlug": "mistral/ministral-3b",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0.00020016",
              "marketCost": "0.00020016",
              "generationId": "gen_01KJ5JY18PZN0DQJ7Q1M69WR0J",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "openai/gpt-5.2",
          "tier": "frontier",
          "status": "success",
          "message": "feat(agent): support resuming subagent sessions via session_id",
          "latencyMs": 2102,
          "costUsd": 0.00839825,
          "inputTokens": 4671,
          "outputTokens": 16,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "openai": {
              "responseId": "resp_06361066894f494800699c7689c9248196bca674d2405859f5",
              "serviceTier": "default"
            },
            "gateway": {
              "routing": {
                "originalModelId": "openai/gpt-5.2",
                "resolvedProvider": "openai",
                "resolvedProviderApiModelId": "gpt-5.2",
                "internalResolvedModelId": "openai:gpt-5.2",
                "fallbacksAvailable": [
                  "azure"
                ],
                "internalReasoning": "Selected openai as preferred provider for gpt-5.2. 1 fallback(s) available: azure",
                "planningReasoning": "BYOK credentials available for: openai. System credentials planned for: openai, azure. Total execution order: openai(BYOK) → openai(system) → azure(system)",
                "canonicalSlug": "openai/gpt-5.2",
                "finalProvider": "openai",
                "attempts": [
                  {
                    "provider": "openai",
                    "internalModelId": "openai:gpt-5.2",
                    "providerApiModelId": "gpt-5.2",
                    "credentialType": "byok",
                    "success": true,
                    "startTime": 1527767.62214,
                    "endTime": 1529511.00048,
                    "statusCode": 200,
                    "providerResponseId": "resp_06361066894f494800699c7689c9248196bca674d2405859f5"
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "openai/gpt-5.2",
                    "canonicalSlug": "openai/gpt-5.2",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0",
              "marketCost": "0.00839825",
              "generationId": "gen_01KJ5JY1VYR6TDTY5FR0RHPRTN",
              "billableWebSearchCalls": 0
            }
          }
        },
        {
          "modelId": "xai/grok-code-fast-1",
          "tier": "small",
          "status": "success",
          "message": "feat(subagent): add support for resuming subagent sessions",
          "latencyMs": 18618,
          "costUsd": 0.00156464,
          "inputTokens": 4831,
          "outputTokens": 422,
          "humanReview": {
            "overallScore": 3,
            "notes": "Pending manual review.",
            "winnerFlag": false
          },
          "providerMetadata": {
            "gateway": {
              "routing": {
                "originalModelId": "xai/grok-code-fast-1",
                "resolvedProvider": "xai",
                "resolvedProviderApiModelId": "grok-code-fast-1",
                "internalResolvedModelId": "xai:grok-code-fast-1",
                "fallbacksAvailable": [],
                "internalReasoning": "Selected xai as preferred provider for grok-code-fast-1. 0 fallback(s) available: ",
                "planningReasoning": "System credentials planned for: xai. Total execution order: xai(system)",
                "canonicalSlug": "xai/grok-code-fast-1",
                "finalProvider": "xai",
                "attempts": [
                  {
                    "provider": "xai",
                    "internalModelId": "xai:grok-code-fast-1",
                    "providerApiModelId": "grok-code-fast-1",
                    "credentialType": "system",
                    "success": true,
                    "startTime": 721969.34778,
                    "endTime": 740220.833321,
                    "statusCode": 200
                  }
                ],
                "modelAttemptCount": 1,
                "modelAttempts": [
                  {
                    "modelId": "xai/grok-code-fast-1",
                    "canonicalSlug": "xai/grok-code-fast-1",
                    "success": false,
                    "providerAttemptCount": 0,
                    "providerAttempts": []
                  }
                ],
                "totalProviderAttemptCount": 0
              },
              "cost": "0.00156464",
              "marketCost": "0.00156464",
              "generationId": "gen_01KJ5JY19ZCQKTAF7R5H1NJBSD",
              "billableWebSearchCalls": 0
            }
          }
        }
      ]
    }
  ],
  "aggregate": {
    "byModel": [
      {
        "modelId": "mistral/ministral-3b",
        "tier": "small",
        "successCount": 2,
        "errorCount": 0,
        "avgLatencyMs": 717,
        "avgCostUsd": 0.0001778,
        "avgScore": 3
      },
      {
        "modelId": "xai/grok-code-fast-1",
        "tier": "small",
        "successCount": 2,
        "errorCount": 0,
        "avgLatencyMs": 17070.5,
        "avgCostUsd": 0.0013554,
        "avgScore": 3
      },
      {
        "modelId": "cerebras/llama3.1-8b",
        "tier": "small",
        "successCount": 2,
        "errorCount": 0,
        "avgLatencyMs": 725.5,
        "avgCostUsd": 0.0004095,
        "avgScore": 3
      },
      {
        "modelId": "openai/gpt-5.2",
        "tier": "frontier",
        "successCount": 2,
        "errorCount": 0,
        "avgLatencyMs": 2229,
        "avgCostUsd": 0.007497,
        "avgScore": 3
      },
      {
        "modelId": "anthropic/claude-opus-4.5",
        "tier": "frontier",
        "successCount": 2,
        "errorCount": 0,
        "avgLatencyMs": 2939.5,
        "avgCostUsd": 0.0274325,
        "avgScore": 3
      },
      {
        "modelId": "anthropic/claude-sonnet-4.6",
        "tier": "frontier",
        "successCount": 2,
        "errorCount": 0,
        "avgLatencyMs": 1862,
        "avgCostUsd": 0.0165525,
        "avgScore": 3
      },
      {
        "modelId": "google/gemini-3-pro-preview",
        "tier": "frontier",
        "successCount": 2,
        "errorCount": 0,
        "avgLatencyMs": 3555.5,
        "avgCostUsd": 0.011674,
        "avgScore": 3
      },
      {
        "modelId": "mistral/codestral",
        "tier": "small",
        "successCount": 2,
        "errorCount": 0,
        "avgLatencyMs": 893.5,
        "avgCostUsd": 0.0013413,
        "avgScore": 3
      }
    ],
    "smallTopModelId": "mistral/ministral-3b",
    "frontierTopModelId": "anthropic/claude-sonnet-4.6"
  }
}
